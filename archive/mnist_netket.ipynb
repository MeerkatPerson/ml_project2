{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6387de74-7f19-446c-9c10-3d201a270a87",
   "metadata": {
    "id": "6387de74-7f19-446c-9c10-3d201a270a87"
   },
   "source": [
    "# Introduction to Deep Learning\n",
    "\n",
    "### Hands-on 2a: MNIST\n",
    "Filippo Vicentini and Giuseppe Carleo\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/PhilipVinc/IntroDeepLearning/blob/master/2a-mnist.ipynb) \n",
    "\n",
    "\n",
    "The objective of this hands-on is to write and optimise an image-classifier that identifies handwritten digits.\n",
    "\n",
    "We will use for this the [MNIST dataset of handwritten digits](http://yann.lecun.com/exdb/mnist/)\n",
    "\n",
    "![title](https://github.com/PhilipVinc/IntroDeepLearning/blob/master/images/mnist.png?raw=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e558598f-2027-45fc-8b92-b8e8ae74215e",
   "metadata": {
    "id": "e558598f-2027-45fc-8b92-b8e8ae74215e"
   },
   "source": [
    "## 0 - Install Requirements\n",
    "\n",
    "For this example notebook we will need jax+flax+optax for the machine-learning part.\n",
    "\n",
    "For the dataset, instead, we will be using `tensorflow_datasets`, which is a submodule of `tensorflow` that makes it easy to download and load into memory large datasets (such as MNIST and many others).\n",
    "\n",
    "If you are running notebook locally, you need to also install `tensorflow` to make `tensorflow_datasets` work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7895a56-6b30-49bc-b07e-1fe5a6a00b09",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d7895a56-6b30-49bc-b07e-1fe5a6a00b09",
    "outputId": "cbc148e3-bf63-467f-f170-e6f34ecd43c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow_datasets in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (4.4.0)\n",
      "Requirement already satisfied: flax in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (0.3.6)\n",
      "Requirement already satisfied: jax in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (0.2.25)\n",
      "Requirement already satisfied: optax in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (0.1.0)\n",
      "Requirement already satisfied: tqdm in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (4.62.3)\n",
      "Requirement already satisfied: netket in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (3.2)\n",
      "Requirement already satisfied: imgaug==0.2.6 in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (0.2.6)\n",
      "Requirement already satisfied: dill in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from tensorflow_datasets) (0.3.4)\n",
      "Requirement already satisfied: promise in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from tensorflow_datasets) (2.3)\n",
      "Requirement already satisfied: attrs>=18.1.0 in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from tensorflow_datasets) (21.2.0)\n",
      "Requirement already satisfied: tensorflow-metadata in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from tensorflow_datasets) (1.5.0)\n",
      "Requirement already satisfied: termcolor in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from tensorflow_datasets) (1.1.0)\n",
      "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from tensorflow_datasets) (5.4.0)\n",
      "Requirement already satisfied: protobuf>=3.12.2 in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from tensorflow_datasets) (3.19.1)\n",
      "Requirement already satisfied: absl-py in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from tensorflow_datasets) (1.0.0)\n",
      "Requirement already satisfied: numpy in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from tensorflow_datasets) (1.20.0)\n",
      "Requirement already satisfied: six in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from tensorflow_datasets) (1.16.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from tensorflow_datasets) (2.26.0)\n",
      "Requirement already satisfied: future in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from tensorflow_datasets) (0.18.2)\n",
      "Requirement already satisfied: msgpack in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from flax) (1.0.3)\n",
      "Requirement already satisfied: matplotlib in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from flax) (3.4.3)\n",
      "Requirement already satisfied: opt_einsum in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from jax) (3.3.0)\n",
      "Requirement already satisfied: scipy>=1.2.1 in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from jax) (1.7.1)\n",
      "Requirement already satisfied: typing_extensions in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from jax) (3.10.0.2)\n",
      "Requirement already satisfied: jaxlib>=0.1.37 in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from optax) (0.1.74)\n",
      "Requirement already satisfied: chex>=0.0.4 in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from optax) (0.1.0)\n",
      "Requirement already satisfied: numba4jax<0.1,>=0.0.1 in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from netket) (0.0.4)\n",
      "Requirement already satisfied: orjson~=3.4 in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from netket) (3.6.4)\n",
      "Requirement already satisfied: numba<0.55,>=0.52 in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from netket) (0.54.1)\n",
      "Requirement already satisfied: plum-dispatch~=1.5.1 in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from netket) (1.5.7)\n",
      "Requirement already satisfied: igraph~=0.9.8 in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from netket) (0.9.8)\n",
      "Requirement already satisfied: scikit-image>=0.11.0 in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from imgaug==0.2.6) (0.19.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from tensorflow-metadata->tensorflow_datasets) (1.53.0)\n",
      "Requirement already satisfied: zipp>=3.1.0; python_version < \"3.10\" in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from importlib-resources; python_version < \"3.9\"->tensorflow_datasets) (3.6.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from requests>=2.19.0->tensorflow_datasets) (2.0.8)\n",
      "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from requests>=2.19.0->tensorflow_datasets) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from requests>=2.19.0->tensorflow_datasets) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from requests>=2.19.0->tensorflow_datasets) (2021.10.8)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from matplotlib->flax) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from matplotlib->flax) (1.3.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from matplotlib->flax) (8.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from matplotlib->flax) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from matplotlib->flax) (2.4.7)\n",
      "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from jaxlib>=0.1.37->optax) (2.0)\n",
      "Requirement already satisfied: dm-tree>=0.1.5 in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from chex>=0.0.4->optax) (0.1.6)\n",
      "Requirement already satisfied: toolz>=0.9.0 in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from chex>=0.0.4->optax) (0.11.2)\n",
      "Requirement already satisfied: cffi>=1.12 in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from numba4jax<0.1,>=0.0.1->netket) (1.14.6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: setuptools in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from numba<0.55,>=0.52->netket) (41.2.0)\n",
      "Requirement already satisfied: llvmlite<0.38,>=0.37.0rc1 in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from numba<0.55,>=0.52->netket) (0.37.0)\n",
      "Requirement already satisfied: texttable>=1.6.2 in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from igraph~=0.9.8->netket) (1.6.4)\n",
      "Requirement already satisfied: networkx>=2.2 in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from scikit-image>=0.11.0->imgaug==0.2.6) (2.6.3)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from scikit-image>=0.11.0->imgaug==0.2.6) (2.13.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from scikit-image>=0.11.0->imgaug==0.2.6) (21.0)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from scikit-image>=0.11.0->imgaug==0.2.6) (1.2.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from scikit-image>=0.11.0->imgaug==0.2.6) (2021.11.2)\n",
      "Requirement already satisfied: pycparser in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from cffi>=1.12->numba4jax<0.1,>=0.0.1->netket) (2.20)\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 21.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Requirements\n",
    "!pip install tensorflow_datasets flax jax optax tqdm netket imgaug==0.2.6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f998ee7-4e9d-4538-b125-5222253ad15b",
   "metadata": {
    "id": "3f998ee7-4e9d-4538-b125-5222253ad15b"
   },
   "source": [
    "### 0.1 - Utility Functions\n",
    "\n",
    "Don't look here. There is nothing interesting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "561535f1-4d9a-4908-bbb7-e63c94d22d47",
   "metadata": {
    "id": "561535f1-4d9a-4908-bbb7-e63c94d22d47"
   },
   "outputs": [],
   "source": [
    "# Utility functions (don't worry. you don't need to understand this one)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def show_img(img, ax=None, title=None):\n",
    "  \"\"\"Shows a single image.\n",
    "  \n",
    "  Must be stored as a 3d-tensor where the last dimension is 1 channel (greyscale)\n",
    "  \"\"\"\n",
    "  if ax is None:\n",
    "    ax = plt.gca()\n",
    "  ax.imshow(img[..., 0], cmap='gray')\n",
    "  ax.set_xticks([])\n",
    "  ax.set_yticks([])\n",
    "  if title:\n",
    "    ax.set_title(title)\n",
    "\n",
    "def show_img_grid(imgs, titles):\n",
    "  \"\"\"Shows a grid of images.\"\"\"\n",
    "  n = int(np.ceil(len(imgs)**.5))\n",
    "  _, axs = plt.subplots(n, n, figsize=(3 * n, 3 * n))\n",
    "  for i, (img, title) in enumerate(zip(imgs, titles)):\n",
    "    show_img(img, axs[i // n][i % n], title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "241cfd9e-6a5e-4257-b3b5-2e7bad914a5e",
   "metadata": {
    "id": "241cfd9e-6a5e-4257-b3b5-2e7bad914a5e"
   },
   "outputs": [],
   "source": [
    "# Import \n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c5988d-c3c3-43d0-abc8-6ceb1c09054d",
   "metadata": {
    "id": "55c5988d-c3c3-43d0-abc8-6ceb1c09054d"
   },
   "source": [
    "## 1 - Setting up the dataset\n",
    "First of all, we need to download the dataset.\n",
    "\n",
    "The MNIST dataset is a standard dataset composed of several 28x28 black/white images representing numbers, and a label corresponding to the number that is represented there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90e05be1-0fd8-4562-8251-f8caa0576d3e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292,
     "referenced_widgets": [
      "fdbbfa9dd9274ac5b5122eb70e8bd166",
      "04701b94470e4411b492e05f32420185",
      "d7aa4fb804ea4a73996663c5d0822eb2",
      "891bacd221794bbfa89a2f02dbdee926",
      "32c1a0067c3a4e7fba9065e92bdbc018",
      "78c429eff6024aa2a512b15e9b8e5e9d",
      "dd1bc9bdf2a84c17be8de44ceb04d62f",
      "55e80ba5b1cf432a9fb796a67a3f78b9",
      "91384fa0fe154c09837d63ce7c101eae",
      "ace16b3606ad493aab790446a3319436",
      "320532e08f5549aca2ef73d7eaa1b355"
     ]
    },
    "id": "90e05be1-0fd8-4562-8251-f8caa0576d3e",
    "outputId": "ccc1f310-b66e-4e56-b6f5-e4071f486641"
   },
   "outputs": [],
   "source": [
    "# We use Tensorflow datasets to download and import data in a simple numpy-tensor format\n",
    "# It's just handy. You could use anything else.\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# Specify the dataset we are interested in\n",
    "ds_builder = tfds.builder('fashion_mnist')\n",
    "\n",
    "# Download the data\n",
    "ds_builder.download_and_prepare()\n",
    "\n",
    "# Get the whole dataset's train set\n",
    "train_ds = tfds.as_numpy(ds_builder.as_dataset(split='train', batch_size=-1))\n",
    "test_ds = tfds.as_numpy(ds_builder.as_dataset(split='test', batch_size=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7b5869-071c-4431-b830-fd837948577d",
   "metadata": {
    "id": "0a7b5869-071c-4431-b830-fd837948577d"
   },
   "source": [
    "The dataset is split into two sub-sets: the training dataset that we will use to 'train' our model, and the 'test' dataset, which the model *never sees* during training, but that we use to check that the model performs well.\n",
    "\n",
    "This is to verify that the model does not simply learn _by heart_ the images in the training dataset, but that it actually _learns_ to generalize and works correctly with images that he did not see before.\n",
    "\n",
    "We can inspect the shape of the training dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc6521ad-6be7-46ab-9cf4-28d24da2d5d9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dc6521ad-6be7-46ab-9cf4-28d24da2d5d9",
    "outputId": "282065e4-7291-4c45-b3b9-451053a9dbb4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset keys: dict_keys(['image', 'label'])\n",
      "The training dataset has shape: (60000, 28, 28, 1) and dtype uint8\n",
      "The test     dataset has shape: (10000, 28, 28, 1) and dtype uint8\n",
      "\n",
      "The training labels have shape: (60000,) and dtype int64\n",
      "The test     labels have shape: (10000,) and dtype int64\n"
     ]
    }
   ],
   "source": [
    "print(\"dataset keys:\", train_ds.keys())\n",
    "print(f\"The training dataset has shape: {train_ds['image'].shape} and dtype {train_ds['image'].dtype}\")\n",
    "print(f\"The test     dataset has shape: {test_ds['image'].shape} and dtype {train_ds['image'].dtype}\")\n",
    "print(\"\")\n",
    "print(f\"The training labels have shape: {train_ds['label'].shape} and dtype {train_ds['label'].dtype}\")\n",
    "print(f\"The test     labels have shape: {test_ds['label'].shape} and dtype {test_ds['label'].dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46c721dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': array([[[[  0],\n",
       "          [  0],\n",
       "          [  0],\n",
       "          ...,\n",
       "          [  0],\n",
       "          [  0],\n",
       "          [  0]],\n",
       " \n",
       "         [[  0],\n",
       "          [  0],\n",
       "          [  0],\n",
       "          ...,\n",
       "          [  0],\n",
       "          [  0],\n",
       "          [  0]],\n",
       " \n",
       "         [[  0],\n",
       "          [  0],\n",
       "          [  0],\n",
       "          ...,\n",
       "          [  0],\n",
       "          [  0],\n",
       "          [  0]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[  0],\n",
       "          [  0],\n",
       "          [  0],\n",
       "          ...,\n",
       "          [  0],\n",
       "          [  0],\n",
       "          [  0]],\n",
       " \n",
       "         [[  0],\n",
       "          [  0],\n",
       "          [  0],\n",
       "          ...,\n",
       "          [  0],\n",
       "          [  0],\n",
       "          [  0]],\n",
       " \n",
       "         [[  0],\n",
       "          [  0],\n",
       "          [  0],\n",
       "          ...,\n",
       "          [  0],\n",
       "          [  0],\n",
       "          [  0]]],\n",
       " \n",
       " \n",
       "        [[[  0],\n",
       "          [  0],\n",
       "          [  0],\n",
       "          ...,\n",
       "          [  0],\n",
       "          [  0],\n",
       "          [  0]],\n",
       " \n",
       "         [[  0],\n",
       "          [  0],\n",
       "          [  0],\n",
       "          ...,\n",
       "          [  0],\n",
       "          [  0],\n",
       "          [  0]],\n",
       " \n",
       "         [[  0],\n",
       "          [  0],\n",
       "          [  0],\n",
       "          ...,\n",
       "          [  0],\n",
       "          [  0],\n",
       "          [  0]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[  0],\n",
       "          [  0],\n",
       "          [  0],\n",
       "          ...,\n",
       "          [  0],\n",
       "          [  0],\n",
       "          [  0]],\n",
       " \n",
       "         [[  0],\n",
       "          [  0],\n",
       "          [  0],\n",
       "          ...,\n",
       "          [  0],\n",
       "          [  0],\n",
       "          [  0]],\n",
       " \n",
       "         [[  0],\n",
       "          [  0],\n",
       "          [  0],\n",
       "          ...,\n",
       "          [  0],\n",
       "          [  0],\n",
       "          [  0]]],\n",
       " \n",
       " \n",
       "        [[[  0],\n",
       "          [  0],\n",
       "          [  0],\n",
       "          ...,\n",
       "          [  0],\n",
       "          [  0],\n",
       "          [  0]],\n",
       " \n",
       "         [[  0],\n",
       "          [  0],\n",
       "          [  0],\n",
       "          ...,\n",
       "          [  0],\n",
       "          [  0],\n",
       "          [  0]],\n",
       " \n",
       "         [[  0],\n",
       "          [  0],\n",
       "          [  0],\n",
       "          ...,\n",
       "          [  0],\n",
       "          [  0],\n",
       "          [  0]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[  0],\n",
       "          [  0],\n",
       "          [  0],\n",
       "          ...,\n",
       "          [  0],\n",
       "          [  0],\n",
       "          [  0]],\n",
       " \n",
       "         [[  0],\n",
       "          [  0],\n",
       "          [  0],\n",
       "          ...,\n",
       "          [  0],\n",
       "          [  0],\n",
       "          [  0]],\n",
       " \n",
       "         [[  0],\n",
       "          [  0],\n",
       "          [  0],\n",
       "          ...,\n",
       "          [  0],\n",
       "          [  0],\n",
       "          [  0]]],\n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       "        [[[  0],\n",
       "          [  0],\n",
       "          [  0],\n",
       "          ...,\n",
       "          [  0],\n",
       "          [  0],\n",
       "          [  0]],\n",
       " \n",
       "         [[  0],\n",
       "          [  0],\n",
       "          [  0],\n",
       "          ...,\n",
       "          [  0],\n",
       "          [  0],\n",
       "          [  0]],\n",
       " \n",
       "         [[  0],\n",
       "          [  0],\n",
       "          [  0],\n",
       "          ...,\n",
       "          [  0],\n",
       "          [  0],\n",
       "          [  0]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[  0],\n",
       "          [  0],\n",
       "          [  0],\n",
       "          ...,\n",
       "          [  0],\n",
       "          [  0],\n",
       "          [  0]],\n",
       " \n",
       "         [[  0],\n",
       "          [  0],\n",
       "          [  0],\n",
       "          ...,\n",
       "          [  0],\n",
       "          [  0],\n",
       "          [  0]],\n",
       " \n",
       "         [[  0],\n",
       "          [  0],\n",
       "          [  0],\n",
       "          ...,\n",
       "          [  0],\n",
       "          [  0],\n",
       "          [  0]]],\n",
       " \n",
       " \n",
       "        [[[  0],\n",
       "          [  0],\n",
       "          [  0],\n",
       "          ...,\n",
       "          [  0],\n",
       "          [  0],\n",
       "          [  0]],\n",
       " \n",
       "         [[  0],\n",
       "          [  0],\n",
       "          [  0],\n",
       "          ...,\n",
       "          [  0],\n",
       "          [  0],\n",
       "          [  0]],\n",
       " \n",
       "         [[  0],\n",
       "          [  0],\n",
       "          [  0],\n",
       "          ...,\n",
       "          [  0],\n",
       "          [ 75],\n",
       "          [ 15]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[  0],\n",
       "          [  0],\n",
       "          [  0],\n",
       "          ...,\n",
       "          [ 64],\n",
       "          [ 38],\n",
       "          [  0]],\n",
       " \n",
       "         [[  0],\n",
       "          [  0],\n",
       "          [  0],\n",
       "          ...,\n",
       "          [  0],\n",
       "          [  0],\n",
       "          [  0]],\n",
       " \n",
       "         [[  0],\n",
       "          [  0],\n",
       "          [  0],\n",
       "          ...,\n",
       "          [  0],\n",
       "          [  0],\n",
       "          [  0]]],\n",
       " \n",
       " \n",
       "        [[[  0],\n",
       "          [  0],\n",
       "          [  0],\n",
       "          ...,\n",
       "          [  0],\n",
       "          [  0],\n",
       "          [  0]],\n",
       " \n",
       "         [[  0],\n",
       "          [  0],\n",
       "          [  0],\n",
       "          ...,\n",
       "          [  0],\n",
       "          [  0],\n",
       "          [  0]],\n",
       " \n",
       "         [[  0],\n",
       "          [  0],\n",
       "          [  0],\n",
       "          ...,\n",
       "          [  0],\n",
       "          [  0],\n",
       "          [  0]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[  0],\n",
       "          [  0],\n",
       "          [  0],\n",
       "          ...,\n",
       "          [150],\n",
       "          [ 66],\n",
       "          [  0]],\n",
       " \n",
       "         [[  0],\n",
       "          [  0],\n",
       "          [  0],\n",
       "          ...,\n",
       "          [  0],\n",
       "          [  0],\n",
       "          [  0]],\n",
       " \n",
       "         [[  0],\n",
       "          [  0],\n",
       "          [  0],\n",
       "          ...,\n",
       "          [  0],\n",
       "          [  0],\n",
       "          [  0]]]], dtype=uint8),\n",
       " 'label': array([2, 1, 8, ..., 6, 9, 9])}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15665ab5-cb0c-4478-a48e-e0515cbe4fef",
   "metadata": {
    "id": "15665ab5-cb0c-4478-a48e-e0515cbe4fef"
   },
   "source": [
    "We can visualize it to understand it a bit more, using an utility function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d044bc34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         ...,\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]],\n",
       "\n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         ...,\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]],\n",
       "\n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         ...,\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         ...,\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]],\n",
       "\n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         ...,\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]],\n",
       "\n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         ...,\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]]],\n",
       "\n",
       "\n",
       "       [[[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         ...,\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]],\n",
       "\n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         ...,\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]],\n",
       "\n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         ...,\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         ...,\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]],\n",
       "\n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         ...,\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]],\n",
       "\n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         ...,\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]]],\n",
       "\n",
       "\n",
       "       [[[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         ...,\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]],\n",
       "\n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         ...,\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]],\n",
       "\n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         ...,\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         ...,\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]],\n",
       "\n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         ...,\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]],\n",
       "\n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         ...,\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         ...,\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]],\n",
       "\n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         ...,\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]],\n",
       "\n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         ...,\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         ...,\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]],\n",
       "\n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         ...,\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]],\n",
       "\n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         ...,\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]]],\n",
       "\n",
       "\n",
       "       [[[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         ...,\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]],\n",
       "\n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         ...,\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]],\n",
       "\n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         ...,\n",
       "         [  0],\n",
       "         [ 75],\n",
       "         [ 15]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         ...,\n",
       "         [ 64],\n",
       "         [ 38],\n",
       "         [  0]],\n",
       "\n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         ...,\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]],\n",
       "\n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         ...,\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]]],\n",
       "\n",
       "\n",
       "       [[[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         ...,\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]],\n",
       "\n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         ...,\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]],\n",
       "\n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         ...,\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         ...,\n",
       "         [150],\n",
       "         [ 66],\n",
       "         [  0]],\n",
       "\n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         ...,\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]],\n",
       "\n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         ...,\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]]]], dtype=uint8)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds['image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e6146cb7-be9d-4206-8b60-ae27699f0444",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 540
    },
    "id": "e6146cb7-be9d-4206-8b60-ae27699f0444",
    "outputId": "d8143b07-dfaf-4b8e-f65c-7fd8dd3f8c42"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x648 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_img_grid(\n",
    "    [train_ds['image'][idx] for idx in range(9)],\n",
    "    [f'label={train_ds[\"label\"][idx]}' for idx in range(9)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d357d877-89e9-41ea-8301-d5fe22693a90",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d357d877-89e9-41ea-8301-d5fe22693a90",
    "outputId": "2a3adc79-bece-4c38-ec07-aea3f15fdd5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean     of the data stored in the images are:  72.94035223214286\n",
      "The variance of the data stored in the images are:  8103.81327192694\n"
     ]
    }
   ],
   "source": [
    "print(\"The mean     of the data stored in the images are: \", np.mean(train_ds['image']))\n",
    "print(\"The variance of the data stored in the images are: \", np.var(train_ds['image']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c9f1e8-b449-4589-a826-3dd5771db7ce",
   "metadata": {
    "id": "73c9f1e8-b449-4589-a826-3dd5771db7ce"
   },
   "source": [
    "We have seen that the data is stored in uint8 (an *unsigned* 8-bit integer which can take values from 0 to 255 ).\n",
    "\n",
    "However it is often preferable when working with Neural Networks to work with floating-point values with values around 0 and variance approximately 1. The reasons are 2:\n",
    "\n",
    " - modern CPUs (and to an extent GPUs) are often faster at working with batches (blocks) of floating-point numbers rather than integers [caveats apply]\n",
    " - Many nonlinear functions used in machine-learning have the nonlinear crossover aroud ~0 or ~1/2, so we want our data to be spread around those values\n",
    " - Most research about how to initialize neural-network layers assumes that the input data has mean 0 and variance 1, so to exploit those results we have to rescale our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "83684f21-5c8e-423d-8c61-9973988fc8cc",
   "metadata": {
    "id": "83684f21-5c8e-423d-8c61-9973988fc8cc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "# Therefore... let's convert the data!\n",
    "train_ds['image'] = jnp.float32(train_ds['image']) / 255.\n",
    "test_ds['image'] = jnp.float32(test_ds['image']) / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d403277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_ds['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e5a79b56-21ac-49ec-9485-2590a18a2748",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e5a79b56-21ac-49ec-9485-2590a18a2748",
    "outputId": "48e66243-0bc1-4eab-9959-a8d4a6b64121"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training dataset has shape: (60000, 28, 28, 1) and dtype float32\n",
      "The test     dataset has shape: (10000, 28, 28, 1) and dtype float32\n",
      "The mean     of the data stored in the images are:  0.2859972\n",
      "The variance of the data stored in the images are:  0.12143051\n"
     ]
    }
   ],
   "source": [
    "print(f\"The training dataset has shape: {train_ds['image'].shape} and dtype {train_ds['image'].dtype}\")\n",
    "print(f\"The test     dataset has shape: {test_ds['image'].shape} and dtype {train_ds['image'].dtype}\")\n",
    "\n",
    "print(\"The mean     of the data stored in the images are: \", np.mean(train_ds['image']))\n",
    "print(\"The variance of the data stored in the images are: \", np.var(train_ds['image']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf695fb-0fab-49f3-81fd-9a23fc7ea311",
   "metadata": {
    "id": "0bf695fb-0fab-49f3-81fd-9a23fc7ea311"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "98e56e14-2a4e-4fad-9d47-809ba4b0a354",
   "metadata": {
    "id": "98e56e14-2a4e-4fad-9d47-809ba4b0a354"
   },
   "source": [
    "## 2 - The model (Neural Network)\n",
    "\n",
    "We want now to define the Model.\n",
    "We will use Flax to do that.\n",
    "\n",
    "We want our network to return a probability distribution for the input to correspond to one of several output labels.\n",
    "\n",
    "e.g: if $x$ is an image, then $f : \\mathbb{R}^{28\\times 28}\\rightarrow \\mathbb{R}^{10}$ and $f^{(i)}(x)$ is the probability that the image $x$ represents a $i\\in[0,9]$\n",
    "\n",
    "To make the output of the network a probability distribution, we can use a softmax function, defined as\n",
    "\n",
    "$$\n",
    "\\sigma_i(x) = \\frac{e^{x_i}}{\\sum_i^K e^{x_i} }  \\text{   for  } i\\in [1,K] \\text{ and } x\\in\\mathbb{R}^K\n",
    "$$\n",
    "\n",
    "We want to use a Feedforward network with 2 Dense Layers, relu-nonlinearity and output softmax using Flax.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88dfb662",
   "metadata": {},
   "source": [
    "***NOTE*** (to myself and whoever else may be interested in this information): we use softmax rather than argmax when training a NN because the argmax wouldn't work with backpropagation (zero derivatives!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8af5cf83-b3e2-4a1d-b204-73f383952134",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8af5cf83-b3e2-4a1d-b204-73f383952134",
    "outputId": "7463208a-8173-4234-a600-86485bb3d402"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages/jax/experimental/stax.py:28: FutureWarning: jax.experimental.stax is deprecated, import jax.example_libraries.stax instead\n",
      "  warnings.warn('jax.experimental.stax is deprecated, '\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "# We import flax.linen as nn\n",
    "# The reason is that flax.nn is old and deprecated and will be removed one day\n",
    "import jax\n",
    "import flax\n",
    "\n",
    "# From now on, use netket as nk wherever the original notebook uses flax.linen as nn!\n",
    "import netket as nk\n",
    "import jax.numpy as jnp\n",
    "\n",
    "from jax.experimental import stax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340267ce",
   "metadata": {},
   "source": [
    "Original suggestion by Prof Carleo: use modRelu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7bf8a1ee-844e-4342-8578-6a0df21cc422",
   "metadata": {
    "id": "7bf8a1ee-844e-4342-8578-6a0df21cc422"
   },
   "outputs": [],
   "source": [
    "def modRelu(z, bias): # relu(|z|+b) * (z / |z|)\n",
    "    norm = jnp.abs(z)\n",
    "    scale = nk.nn.relu(norm + bias) / (norm + 1e-6)\n",
    "    scaled = jax.lax.complex(jnp.real(z)*scale, jnp.imag(z)*scale)\n",
    "    return scaled\n",
    "modRelu=jax.jit(modRelu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b410bbd3",
   "metadata": {},
   "source": [
    "New suggestion by Dian:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ec94b8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complex_relu(z):\n",
    "    return jnp.where(z.real > 0, z, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "IbeqZDidofc8",
   "metadata": {
    "id": "IbeqZDidofc8"
   },
   "source": [
    " /!\\ You can't use max_pool with complex numbers\n",
    " /!\\ To apply dropout you need to add a parameter to init and apply :\n",
    "\n",
    "logits = model.apply({'params': params}, inputs=inputs, rngs={'dropout': dropout_rng})\n",
    "pars = model.init({'params': jax.random.PRNGKey(seed), 'dropout': jax.random.PRNGKey(seed_dropout)}, sample_input)\n",
    "\n",
    " But be careful, RNG is hell with jax but before wondering about dropout we need to make this simple model work\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "sCGPpmwUkdNb",
   "metadata": {
    "id": "sCGPpmwUkdNb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nclass Model(nk.nn.Module):\\n  n_classes : int = 10\\n  @nk.nn.compact\\n  # Provide a constructor to register a new parameter \\n  # and return its initial value\\n  def __call__(self, x):\\n    dropout_rng = self.make_rng('dropout')\\n    x = nk.nn.Conv(features=32, kernel_size=(3, 3))(x)\\n    x = nk.nn.relu(x)\\n    x = flax.linen.avg_pool(x, window_shape=(2, 2), strides=(2, 2)) # With max pool it diverges. Don't ask me why\\n\\n    \\n\\n    x = nk.nn.Conv(features=64, kernel_size=(3, 3))(x)\\n\\n    x = flax.linen.Dropout(0.5, deterministic=True)(x) #DROPOUT 1\\n\\n    x = nk.nn.relu(x)\\n    x = flax.linen.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\\n\\n    x = x.reshape((x.shape[0], -1)) # Flatten\\n    x = nk.nn.Dense(features=256)(x)\\n    x = nk.nn.relu(x)\\n\\n    x = flax.linen.Dropout(0.5, deterministic=True)(x) # DROPOUT 2\\n\\n    x = nk.nn.Dense(features=10)(x)    # There are 10 classes in MNIST\\n    \\n    x = nk.nn.softmax(x)\\n    return x\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This model is from https://github.com/8bitmp3/JAX-Flax-Tutorial-Image-Classification-with-Linen with 2 dropout layers \n",
    "# I suggest that we use this model and transform it to complex which is what I'm trying to do in the cell just below\n",
    "\"\"\"\n",
    "class Model(nk.nn.Module):\n",
    "  n_classes : int = 10\n",
    "  @nk.nn.compact\n",
    "  # Provide a constructor to register a new parameter \n",
    "  # and return its initial value\n",
    "  def __call__(self, x):\n",
    "    dropout_rng = self.make_rng('dropout')\n",
    "    x = nk.nn.Conv(features=32, kernel_size=(3, 3))(x)\n",
    "    x = nk.nn.relu(x)\n",
    "    x = flax.linen.avg_pool(x, window_shape=(2, 2), strides=(2, 2)) # With max pool it diverges. Don't ask me why\n",
    "\n",
    "    \n",
    "\n",
    "    x = nk.nn.Conv(features=64, kernel_size=(3, 3))(x)\n",
    "\n",
    "    x = flax.linen.Dropout(0.5, deterministic=True)(x) #DROPOUT 1\n",
    "\n",
    "    x = nk.nn.relu(x)\n",
    "    x = flax.linen.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
    "\n",
    "    x = x.reshape((x.shape[0], -1)) # Flatten\n",
    "    x = nk.nn.Dense(features=256)(x)\n",
    "    x = nk.nn.relu(x)\n",
    "\n",
    "    x = flax.linen.Dropout(0.5, deterministic=True)(x) # DROPOUT 2\n",
    "\n",
    "    x = nk.nn.Dense(features=10)(x)    # There are 10 classes in MNIST\n",
    "    \n",
    "    x = nk.nn.softmax(x)\n",
    "    return x\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ePoAUw5oqWa3",
   "metadata": {
    "id": "ePoAUw5oqWa3"
   },
   "outputs": [],
   "source": [
    "# Same model as above but complex\n",
    "\n",
    "class Model(nk.nn.Module):\n",
    "  n_classes : int = 10\n",
    "  @nk.nn.compact\n",
    "  # Provide a constructor to register a new parameter \n",
    "  # and return its initial value\n",
    "  def __call__(self, x):\n",
    "\n",
    "    x = nk.nn.Conv(features=32, kernel_size=(3, 3), dtype=complex)(x)\n",
    "\n",
    "    print(\"First conv layer!\")\n",
    "    \n",
    "    print(x.shape)\n",
    "    \n",
    "    x = complex_relu(x)\n",
    "    \n",
    "    print(\"First complex relu comp.\")\n",
    "    \n",
    "    print(x.shape)\n",
    "\n",
    "    x = flax.linen.avg_pool(x, window_shape=(2, 2), strides=(2, 2)) \n",
    "    \n",
    "    print(\"First avg pool\")\n",
    "    \n",
    "    print(x.shape)\n",
    "    \n",
    "    x = nk.nn.Conv(features=64, kernel_size=(3, 3), dtype=complex)(x)\n",
    "\n",
    "    print(\"2nd conv layer!\")\n",
    "    \n",
    "    print(x.shape)\n",
    "    \n",
    "    x = complex_relu(x)\n",
    "\n",
    "    print(\"2nd complex relu comp.\")\n",
    "    \n",
    "    print(x.shape)\n",
    "    \n",
    "    x = flax.linen.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
    "    \n",
    "    print(\"2nd avg pool\")\n",
    "\n",
    "    print(x.shape)\n",
    "    \n",
    "    x = x.reshape((x.shape[0], -1)) # Flatten\n",
    "    \n",
    "    x = nk.nn.Dense(features=256, dtype=complex)(x)\n",
    "\n",
    "    x = complex_relu(x)\n",
    "\n",
    "    x = nk.nn.Dense(features=10, dtype=complex)(x)    # There are 10 classes in MNIST\n",
    "\n",
    "    x = jnp.abs(x) #<= I guess this isn't required anymore?\n",
    "\n",
    "    # In the Jax tutorial, log_softmax is used - should we use it too?\n",
    "    # => let's try\n",
    "    x = nk.nn.log_softmax(x)\n",
    "\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1kVjLXlnBgE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "e1kVjLXlnBgE",
    "outputId": "bcca5487-c33a-4ced-fe7c-050f70a4ff33"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nclass Model(nk.nn.Module):\\n  n_classes : int = 10\\n  @nk.nn.compact\\n  # Provide a constructor to register a new parameter \\n  # and return its initial value\\n  def __call__(self, x):\\n    dropout_rng = self.make_rng('dropout')\\n    x = nk.nn.Conv(features=10, kernel_size=(5, 5))(x)\\n    x = nk.nn.relu(x)\\n    x = flax.linen.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\\n\\n    \\n\\n    x = nk.nn.Conv(features=20, kernel_size=(5, 5))(x)\\n\\n    x = flax.linen.Dropout(0.5, deterministic=True)(x)\\n\\n    x = nk.nn.relu(x)\\n    x = flax.linen.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\\n\\n    x = x.reshape((x.shape[0], -1)) # Flatten\\n    x = nk.nn.Dense(features=320)(x)\\n\\n    x = nk.nn.relu(x)\\n\\n    #x = flax.linen.Dropout(0.5, deterministic=True)(x)\\n    x = nk.nn.Dense(features=10)(x)    # There are 10 classes in MNIST\\n\\n    x = nk.nn.softmax(x)\\n    return x\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# New model with other parameters which is not complex but performing much better\n",
    "# works with a low learning rate\n",
    "\"\"\"\n",
    "class Model(nk.nn.Module):\n",
    "  n_classes : int = 10\n",
    "  @nk.nn.compact\n",
    "  # Provide a constructor to register a new parameter \n",
    "  # and return its initial value\n",
    "  def __call__(self, x):\n",
    "    dropout_rng = self.make_rng('dropout')\n",
    "    x = nk.nn.Conv(features=10, kernel_size=(5, 5))(x)\n",
    "    x = nk.nn.relu(x)\n",
    "    x = flax.linen.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
    "\n",
    "    \n",
    "\n",
    "    x = nk.nn.Conv(features=20, kernel_size=(5, 5))(x)\n",
    "\n",
    "    x = flax.linen.Dropout(0.5, deterministic=True)(x)\n",
    "\n",
    "    x = nk.nn.relu(x)\n",
    "    x = flax.linen.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
    "\n",
    "    x = x.reshape((x.shape[0], -1)) # Flatten\n",
    "    x = nk.nn.Dense(features=320)(x)\n",
    "\n",
    "    x = nk.nn.relu(x)\n",
    "\n",
    "    #x = flax.linen.Dropout(0.5, deterministic=True)(x)\n",
    "    x = nk.nn.Dense(features=10)(x)    # There are 10 classes in MNIST\n",
    "\n",
    "    x = nk.nn.softmax(x)\n",
    "    return x\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "add7d9bd-8028-43e0-b62f-d1c8f05b0de7",
   "metadata": {
    "id": "add7d9bd-8028-43e0-b62f-d1c8f05b0de7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First conv layer!\n",
      "(1, 28, 28, 32)\n",
      "First complex relu comp.\n",
      "(1, 28, 28, 32)\n",
      "First avg pool\n",
      "(1, 14, 14, 32)\n",
      "2nd conv layer!\n",
      "(1, 14, 14, 64)\n",
      "2nd complex relu comp.\n",
      "(1, 14, 14, 64)\n",
      "2nd avg pool\n",
      "(1, 7, 7, 64)\n"
     ]
    }
   ],
   "source": [
    "seed = 123\n",
    "seed_dropout = 0\n",
    "\n",
    "model = Model(n_classes=10)\n",
    "\n",
    "sample_input = jnp.ones([1, 28, 28, 1])\n",
    "\n",
    "# Dropout was added (compared to Deep Learning Tut - why?)\n",
    "\n",
    "key = {'params': jax.random.PRNGKey(seed), 'dropout': jax.random.PRNGKey(seed_dropout)}\n",
    "pars = model.init(key, sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "qFUGKZi6tX7r",
   "metadata": {
    "id": "qFUGKZi6tX7r"
   },
   "outputs": [],
   "source": [
    "a, b = model.init_with_output(key, jnp.ones([50,28,28,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "QnlCRmVhRIBk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QnlCRmVhRIBk",
    "outputId": "0099a33c-eef6-4d7a-eb7c-6d7e7dacb9b0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([-23.05910344, -23.05910344, -23.05910344, -23.05910344,\n",
       "             -23.05910344, -23.05910344, -23.05910344, -23.05910344,\n",
       "             -23.05910344, -23.05910344, -23.05910344, -23.05910344,\n",
       "             -23.05910344, -23.05910344, -23.05910344, -23.05910344,\n",
       "             -23.05910344, -23.05910344, -23.05910344, -23.05910344,\n",
       "             -23.05910344, -23.05910344, -23.05910344, -23.05910344,\n",
       "             -23.05910344, -23.05910344, -23.05910344, -23.05910344,\n",
       "             -23.05910344, -23.05910344, -23.05910344, -23.05910344,\n",
       "             -23.05910344, -23.05910344, -23.05910344, -23.05910344,\n",
       "             -23.05910344, -23.05910344, -23.05910344, -23.05910344,\n",
       "             -23.05910344, -23.05910344, -23.05910344, -23.05910344,\n",
       "             -23.05910344, -23.05910344, -23.05910344, -23.05910344,\n",
       "             -23.05910344, -23.05910344], dtype=float64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1324af-5409-4a2c-9fc3-1ae9e09e009b",
   "metadata": {
    "id": "0b1324af-5409-4a2c-9fc3-1ae9e09e009b"
   },
   "source": [
    "Let's initialize the model:\n",
    " \n",
    " - We need a seed for the RNG that generates the initial weights\n",
    " - We need a sample input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6Se8f-XT00",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3b6Se8f-XT00",
    "outputId": "48749140-f9c4-440c-95b0-eb8232e74a86"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenDict({\n",
       "    params: {\n",
       "        Conv_0: {\n",
       "            kernel: DeviceArray([[[[-5.82772169e-02+0.29194363j,\n",
       "                            -6.28507523e-02+0.09604123j,\n",
       "                            -1.58169942e-01-0.30979609j,\n",
       "                             1.08829532e-02-0.4999597j ,\n",
       "                             2.83268561e-01+0.27674104j,\n",
       "                            -1.16125211e-01+0.26254788j,\n",
       "                             1.03524338e-01+0.34902887j,\n",
       "                            -1.18536110e-01-0.25907359j,\n",
       "                            -2.82146829e-01+0.1126028j ,\n",
       "                             2.90606700e-01-0.1992909j ,\n",
       "                            -3.46378961e-01+0.45473043j,\n",
       "                             1.70997254e-01+0.28729596j,\n",
       "                            -2.51380538e-02-0.25188267j,\n",
       "                            -3.53411562e-02+0.2186729j ,\n",
       "                            -4.17210340e-01+0.17080983j,\n",
       "                            -5.64841642e-01-0.00770295j,\n",
       "                            -1.57674066e-01+0.35771942j,\n",
       "                            -4.06999589e-01+0.09988808j,\n",
       "                             6.07992434e-02+0.11466526j,\n",
       "                            -5.21738380e-02-0.26863156j,\n",
       "                             5.89096861e-02-0.37716778j,\n",
       "                             3.38410127e-01+0.22375623j,\n",
       "                            -2.14582319e-01+0.17278462j,\n",
       "                             2.57354722e-02+0.18236199j,\n",
       "                            -2.34835469e-01-0.20868357j,\n",
       "                             5.64222673e-02+0.46594636j,\n",
       "                             1.85449687e-01+0.10748656j,\n",
       "                             1.52670390e-01-0.30321162j,\n",
       "                            -7.25327487e-03+0.14353004j,\n",
       "                             8.91699445e-02+0.05394211j,\n",
       "                             2.95930582e-01-0.07520828j,\n",
       "                             3.83531821e-01-0.42912816j]],\n",
       "            \n",
       "                          [[ 4.65455313e-01+0.16969507j,\n",
       "                             4.45192145e-02-0.09911595j,\n",
       "                             1.28832162e-01+0.36074533j,\n",
       "                            -4.60070966e-01-0.04548388j,\n",
       "                            -4.86528676e-01-0.38066332j,\n",
       "                             2.97875019e-01-0.06062324j,\n",
       "                            -4.37691109e-01-0.24360865j,\n",
       "                             2.66735112e-01-0.20001695j,\n",
       "                            -3.83404115e-01-0.13304939j,\n",
       "                            -2.49620001e-01-0.27442535j,\n",
       "                             2.91125299e-01-0.07268248j,\n",
       "                            -7.68237208e-02+0.07190413j,\n",
       "                             3.06566131e-02+0.07100754j,\n",
       "                             1.37894311e-01-0.28992018j,\n",
       "                            -1.51620311e-01-0.06265148j,\n",
       "                             4.74075401e-01+0.08399173j,\n",
       "                             1.00431222e-02-0.01724242j,\n",
       "                             3.20919016e-01-0.16168391j,\n",
       "                            -1.30881668e-01+0.41248175j,\n",
       "                             6.42165797e-02+0.23126926j,\n",
       "                            -2.70506755e-01+0.0327286j ,\n",
       "                            -6.87627263e-02+0.20045106j,\n",
       "                             4.22815020e-01-0.42458519j,\n",
       "                            -2.20527858e-01+0.44531498j,\n",
       "                             3.02013447e-02+0.00196431j,\n",
       "                            -1.66882567e-01-0.077039j  ,\n",
       "                            -2.26486890e-01-0.13343278j,\n",
       "                             4.92276663e-02+0.19865883j,\n",
       "                            -6.73487840e-01+0.07554825j,\n",
       "                            -4.70283724e-02+0.00355684j,\n",
       "                             1.52849796e-01+0.23564213j,\n",
       "                            -2.68834309e-01+0.04167445j]],\n",
       "            \n",
       "                          [[ 1.31337563e-01+0.19784022j,\n",
       "                             1.34947778e-01-0.19905514j,\n",
       "                            -1.20995806e-01+0.1689075j ,\n",
       "                            -1.02423516e-01-0.32502757j,\n",
       "                            -4.14050942e-02-0.06872771j,\n",
       "                            -5.94909332e-01-0.13727102j,\n",
       "                            -4.66014168e-01+0.20016811j,\n",
       "                             3.95181329e-01-0.31847392j,\n",
       "                            -1.86189463e-01+0.46722804j,\n",
       "                            -4.46167800e-01-0.02220119j,\n",
       "                            -2.05718545e-01+0.4047332j ,\n",
       "                            -2.99565208e-01+0.45409792j,\n",
       "                             1.11744540e-01+0.06490488j,\n",
       "                             1.01180570e-01-0.1284739j ,\n",
       "                            -2.12778891e-01-0.07397417j,\n",
       "                            -1.96000604e-01+0.2647744j ,\n",
       "                             8.63382146e-02-0.2381889j ,\n",
       "                            -5.35306342e-02-0.27868539j,\n",
       "                            -3.71553899e-01+0.11416667j,\n",
       "                            -1.10271058e-01-0.03108321j,\n",
       "                             4.83083863e-02+0.16623439j,\n",
       "                            -3.69328210e-02+0.13776907j,\n",
       "                             9.09598016e-02+0.50453343j,\n",
       "                             3.99972928e-01-0.20683521j,\n",
       "                            -3.46648053e-01+0.12255855j,\n",
       "                            -2.04005836e-01+0.1160271j ,\n",
       "                             4.22887929e-01+0.06906772j,\n",
       "                            -1.71728406e-01-0.28962197j,\n",
       "                            -2.38949539e-01+0.16995273j,\n",
       "                            -3.66941500e-01+0.17839868j,\n",
       "                             5.10887784e-01-0.03518502j,\n",
       "                             1.11747714e-01+0.00320047j]]],\n",
       "            \n",
       "            \n",
       "                         [[[ 9.17314916e-02-0.01647462j,\n",
       "                             1.02772584e-01-0.27097363j,\n",
       "                            -2.98738912e-01+0.15828588j,\n",
       "                             1.75576195e-01-0.34966807j,\n",
       "                             3.08409831e-01+0.09318589j,\n",
       "                            -3.00829550e-01+0.26578184j,\n",
       "                            -2.81444470e-01-0.12796033j,\n",
       "                            -1.47493192e-01-0.02701097j,\n",
       "                             2.09723494e-01-0.26606408j,\n",
       "                             1.19500597e-01+0.44276579j,\n",
       "                             9.01913473e-02-0.18678575j,\n",
       "                             9.48488007e-02+0.02455686j,\n",
       "                            -2.03318125e-02+0.1431407j ,\n",
       "                            -4.41519639e-01-0.05749849j,\n",
       "                            -7.06304725e-03-0.50593537j,\n",
       "                            -3.17137282e-01+0.10494129j,\n",
       "                             2.09246436e-01-0.01201394j,\n",
       "                            -1.19614203e-01-0.01628797j,\n",
       "                            -3.27703169e-01+0.14294895j,\n",
       "                            -5.00726120e-01-0.12081943j,\n",
       "                            -1.62422826e-01+0.4898503j ,\n",
       "                             2.23663256e-01+0.11144704j,\n",
       "                            -1.10497757e-01-0.27354064j,\n",
       "                            -3.81503008e-01-0.11383629j,\n",
       "                            -4.17470489e-01+0.14791358j,\n",
       "                             4.27942881e-01+0.11358435j,\n",
       "                             2.77157518e-02-0.29265553j,\n",
       "                             3.49300317e-01-0.15911216j,\n",
       "                             1.42926767e-01+0.3023749j ,\n",
       "                             1.56340259e-01-0.04725258j,\n",
       "                             1.29001330e-01+0.20402458j,\n",
       "                            -9.73109453e-02-0.4780939j ]],\n",
       "            \n",
       "                          [[-3.38621171e-02+0.00972805j,\n",
       "                            -8.88143429e-02-0.17647618j,\n",
       "                            -1.28514666e-01-0.13641725j,\n",
       "                             1.76703349e-01-0.0736672j ,\n",
       "                            -1.62683400e-01+0.32632315j,\n",
       "                             4.35843372e-01+0.31027645j,\n",
       "                            -1.02650915e-02-0.05803134j,\n",
       "                            -1.14628728e-01+0.08293257j,\n",
       "                             1.62502649e-01-0.12925166j,\n",
       "                             1.75797746e-01-0.41234123j,\n",
       "                             3.82428563e-01-0.04031118j,\n",
       "                             7.58243946e-02+0.07714728j,\n",
       "                            -1.40538987e-01+0.07384407j,\n",
       "                             2.97004205e-03+0.07569024j,\n",
       "                            -2.36873051e-01+0.01632524j,\n",
       "                            -1.23143323e-01+0.19888261j,\n",
       "                             5.64407582e-02-0.08754598j,\n",
       "                             5.76650946e-01-0.088516j  ,\n",
       "                             3.92816640e-01+0.13630773j,\n",
       "                            -2.98461993e-01-0.00614085j,\n",
       "                            -3.59981930e-01+0.09294338j,\n",
       "                            -1.00012318e-01-0.31630186j,\n",
       "                             6.15628505e-03+0.05683349j,\n",
       "                             7.76100853e-02+0.24984293j,\n",
       "                             2.44846445e-01-0.01565107j,\n",
       "                             2.56005261e-01-0.43230374j,\n",
       "                            -6.06842781e-02+0.1766803j ,\n",
       "                             1.96762619e-01-0.21434604j,\n",
       "                            -2.79340864e-01-0.05758126j,\n",
       "                            -1.24362691e-01-0.01320749j,\n",
       "                             4.05836960e-01-0.19946218j,\n",
       "                             2.77360471e-02-0.28048426j]],\n",
       "            \n",
       "                          [[ 2.12103635e-01-0.24963367j,\n",
       "                            -1.58126358e-01-0.29755403j,\n",
       "                            -1.69064596e-01+0.25190175j,\n",
       "                             2.64634906e-01-0.17310247j,\n",
       "                            -4.35630429e-02-0.1589803j ,\n",
       "                            -1.97705084e-01-0.0615922j ,\n",
       "                             8.27253199e-02-0.44197195j,\n",
       "                             5.09353440e-02-0.2070019j ,\n",
       "                             6.40800129e-02-0.0585422j ,\n",
       "                             4.75673179e-01+0.01414773j,\n",
       "                            -2.32592214e-01+0.17513044j,\n",
       "                             1.49170926e-01-0.42126045j,\n",
       "                             4.15132558e-01+0.03244554j,\n",
       "                             6.92861828e-02+0.25063419j,\n",
       "                            -7.20308362e-02+0.19017767j,\n",
       "                             6.94408531e-02-0.65856927j,\n",
       "                             1.53078994e-01-0.42065473j,\n",
       "                            -6.73523515e-02-0.10723411j,\n",
       "                             1.38913488e-01+0.31812856j,\n",
       "                            -4.20938914e-01+0.47591494j,\n",
       "                             9.42263507e-02+0.17675824j,\n",
       "                            -3.98793378e-02+0.09027056j,\n",
       "                            -4.85884175e-01-0.16628469j,\n",
       "                            -1.78986522e-01-0.05446202j,\n",
       "                            -2.59542159e-01+0.03698819j,\n",
       "                            -1.70180425e-02-0.1836004j ,\n",
       "                             3.66286976e-01-0.25609007j,\n",
       "                            -1.42908236e-01+0.2555806j ,\n",
       "                             1.46042989e-01-0.24173491j,\n",
       "                            -1.75165554e-01-0.02684708j,\n",
       "                            -2.42777661e-01+0.4293572j ,\n",
       "                             3.65657930e-01+0.16579777j]]],\n",
       "            \n",
       "            \n",
       "                         [[[-1.65713976e-01+0.26355002j,\n",
       "                            -1.69234050e-01-0.23794053j,\n",
       "                             6.08910710e-01+0.24337208j,\n",
       "                             3.45926220e-02+0.06593984j,\n",
       "                             1.81095405e-01-0.02973482j,\n",
       "                            -3.11937500e-01+0.5073884j ,\n",
       "                            -2.47721538e-02-0.15657618j,\n",
       "                            -1.05550891e-01+0.51343433j,\n",
       "                             1.87220324e-02+0.0353375j ,\n",
       "                             1.43370799e-02-0.65758382j,\n",
       "                             1.90979380e-01-0.00700097j,\n",
       "                            -2.85194745e-01+0.3869596j ,\n",
       "                             5.96754910e-03+0.15648515j,\n",
       "                             2.04046087e-01-0.11630697j,\n",
       "                            -4.28293581e-01+0.33981302j,\n",
       "                             5.17643677e-02+0.07618326j,\n",
       "                            -2.37581000e-02+0.04194581j,\n",
       "                             2.23773491e-01-0.0974521j ,\n",
       "                            -1.01277189e-01-0.35554906j,\n",
       "                             1.01092570e-01-0.57834448j,\n",
       "                            -5.51409430e-02+0.2023809j ,\n",
       "                            -4.62393338e-02+0.02420879j,\n",
       "                             2.53483992e-01-0.47274328j,\n",
       "                             1.38544325e-01-0.24194868j,\n",
       "                             1.92647824e-01-0.26216637j,\n",
       "                            -9.39734767e-02+0.53749162j,\n",
       "                            -5.58385422e-01+0.39526808j,\n",
       "                             1.50814418e-01-0.26544316j,\n",
       "                            -2.38579971e-01-0.20166652j,\n",
       "                            -1.83996134e-01-0.19465121j,\n",
       "                             2.91017749e-01+0.12858615j,\n",
       "                            -1.22204928e-01+0.50181336j]],\n",
       "            \n",
       "                          [[-2.71400732e-01+0.06216103j,\n",
       "                            -2.70149113e-01-0.27350068j,\n",
       "                            -4.44599945e-01+0.14547533j,\n",
       "                             2.10016517e-01+0.18453707j,\n",
       "                            -7.88364445e-02+0.22357918j,\n",
       "                            -3.02051389e-01-0.04990667j,\n",
       "                             5.02670651e-03-0.302188j  ,\n",
       "                            -2.30489999e-01+0.35619846j,\n",
       "                             1.65220036e-01+0.11698844j,\n",
       "                            -2.92331599e-01-0.09748223j,\n",
       "                             2.41647072e-01-0.19352682j,\n",
       "                            -1.58320852e-01+0.19273724j,\n",
       "                             1.47314223e-01+0.11828216j,\n",
       "                            -2.14854165e-01-0.24507219j,\n",
       "                            -1.92521517e-01-0.08960804j,\n",
       "                            -9.77486978e-02-0.09083921j,\n",
       "                             2.98158040e-02-0.46621098j,\n",
       "                             2.43381506e-01+0.1197826j ,\n",
       "                            -3.34197019e-01-0.38215748j,\n",
       "                             3.35430215e-02+0.00315037j,\n",
       "                             1.39155747e-01-0.02541987j,\n",
       "                            -5.08076314e-02+0.17773143j,\n",
       "                             7.46316772e-02+0.40368196j,\n",
       "                            -1.51880935e-02-0.13286858j,\n",
       "                             2.09335532e-01+0.40252639j,\n",
       "                             5.86994946e-02+0.14959457j,\n",
       "                            -2.41993342e-01-0.21860524j,\n",
       "                             4.29300233e-01+0.25884083j,\n",
       "                             7.37742360e-02+0.12938958j,\n",
       "                            -3.23456054e-01+0.13074225j,\n",
       "                            -2.12615534e-01-0.05478065j,\n",
       "                            -2.42739903e-01-0.30620546j]],\n",
       "            \n",
       "                          [[ 4.16463430e-03+0.07568077j,\n",
       "                            -5.01432454e-02-0.17625428j,\n",
       "                             8.68891538e-02+0.18680103j,\n",
       "                             3.90065019e-05-0.1120699j ,\n",
       "                             1.41673713e-01-0.32947174j,\n",
       "                            -2.33091085e-02+0.44082781j,\n",
       "                            -3.83442492e-01+0.02510178j,\n",
       "                             2.41988113e-01-0.13093929j,\n",
       "                             3.78881584e-02-0.2081493j ,\n",
       "                            -2.08082260e-01-0.13561444j,\n",
       "                             2.33757034e-01+0.26618438j,\n",
       "                             1.42874155e-01-0.12693474j,\n",
       "                             1.66842357e-01+0.24498805j,\n",
       "                            -6.66176726e-02-0.19386552j,\n",
       "                            -2.25421945e-01+0.12950458j,\n",
       "                             2.93660612e-01-0.10434983j,\n",
       "                             1.85572084e-01-0.06116186j,\n",
       "                            -1.96672198e-01+0.17010717j,\n",
       "                             7.56858065e-02+0.09749412j,\n",
       "                             1.04612882e-01+0.19861781j,\n",
       "                            -3.02512646e-01-0.07832748j,\n",
       "                            -2.51633234e-02+0.08985143j,\n",
       "                             1.21014414e-01+0.22096399j,\n",
       "                            -8.53234613e-03-0.23499288j,\n",
       "                             2.25237004e-01+0.19800504j,\n",
       "                             2.05806786e-01+0.18464689j,\n",
       "                             3.20784958e-01-0.21105843j,\n",
       "                             4.81668822e-01-0.21893194j,\n",
       "                             2.49491202e-01-0.58720921j,\n",
       "                             8.74760954e-02-0.55805649j,\n",
       "                             1.41046021e-01+0.09014585j,\n",
       "                            -3.17775884e-01-0.08730256j]]]], dtype=complex128),\n",
       "            bias: DeviceArray([0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
       "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
       "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
       "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
       "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j], dtype=complex128),\n",
       "        },\n",
       "        Conv_1: {\n",
       "            kernel: DeviceArray([[[[ 0.03482234+0.03095743j, -0.03493748-0.02076547j,\n",
       "                            -0.04375343-0.0239546j , ...,  0.02491834+0.01291011j,\n",
       "                            -0.0175787 +0.03157479j,  0.07051917-0.05662623j],\n",
       "                           [ 0.00472411+0.03592918j, -0.00213038+0.07487791j,\n",
       "                             0.04308604+0.00872155j, ...,  0.02167122-0.00605535j,\n",
       "                            -0.03683185+0.1008195j , -0.00219845-0.06815094j],\n",
       "                           [ 0.02730436+0.04646041j, -0.06775723+0.03166591j,\n",
       "                             0.0743866 -0.02367132j, ..., -0.07077232+0.02137569j,\n",
       "                             0.04555017+0.00521124j, -0.01108357+0.01460357j],\n",
       "                           ...,\n",
       "                           [ 0.00923507+0.01248469j, -0.04096933+0.06736743j,\n",
       "                            -0.01098566-0.03371005j, ...,  0.00806781+0.04394274j,\n",
       "                             0.00497748-0.01746109j,  0.03157706-0.02370416j],\n",
       "                           [ 0.04552322+0.01021606j,  0.02824224-0.02919954j,\n",
       "                             0.0126067 +0.03331684j, ...,  0.04982284-0.02595386j,\n",
       "                             0.03576543-0.028629j  ,  0.01002036-0.01151737j],\n",
       "                           [-0.01795196+0.00980297j,  0.01680092+0.09289152j,\n",
       "                            -0.01398638+0.02430201j, ..., -0.00116731+0.03409231j,\n",
       "                            -0.02503092-0.02289507j, -0.07768832-0.00140969j]],\n",
       "            \n",
       "                          [[-0.03096076-0.02881452j,  0.03627845-0.01467034j,\n",
       "                             0.00599171-0.04531322j, ...,  0.00599117-0.06008617j,\n",
       "                             0.04869657-0.04575525j,  0.04349168+0.00101699j],\n",
       "                           [ 0.01870701-0.01487339j,  0.00485689+0.05420156j,\n",
       "                            -0.03220804+0.04769806j, ...,  0.04629443+0.00580715j,\n",
       "                             0.00637359+0.02214924j, -0.03487761+0.03015829j],\n",
       "                           [-0.02151351-0.06106704j, -0.02835454+0.07892759j,\n",
       "                            -0.00222006+0.00642612j, ...,  0.02263997-0.09400637j,\n",
       "                             0.00506652+0.01334276j, -0.02594505+0.02967361j],\n",
       "                           ...,\n",
       "                           [ 0.00711393-0.00536838j,  0.02448177+0.00358612j,\n",
       "                            -0.03083912-0.09801801j, ...,  0.02177475-0.00191255j,\n",
       "                             0.0419647 +0.01189472j,  0.00596233+0.01098253j],\n",
       "                           [-0.05743581-0.04339249j, -0.01542497+0.01416307j,\n",
       "                            -0.03069013+0.01232839j, ...,  0.00174241+0.04468443j,\n",
       "                             0.03875687+0.03249929j,  0.00881621-0.0734093j ],\n",
       "                           [ 0.00591108-0.01241227j, -0.0112367 -0.02459668j,\n",
       "                            -0.01826496-0.06012163j, ...,  0.0004941 +0.01424768j,\n",
       "                            -0.00232885+0.01250343j, -0.01772189-0.01049671j]],\n",
       "            \n",
       "                          [[ 0.04086556-0.01025014j, -0.00130935-0.00724153j,\n",
       "                            -0.02486065+0.01683304j, ...,  0.05992134-0.04015754j,\n",
       "                            -0.02696367-0.04635438j, -0.0397663 -0.07601598j],\n",
       "                           [-0.03840074+0.03126338j,  0.01554346+0.0719401j ,\n",
       "                            -0.04656709-0.00064538j, ..., -0.04164648-0.01645123j,\n",
       "                             0.03737531-0.08720096j, -0.08797581-0.02663946j],\n",
       "                           [ 0.06617318+0.02827778j, -0.05194732-0.02061324j,\n",
       "                            -0.00609713-0.0346503j , ..., -0.01115417-0.00566343j,\n",
       "                             0.02347407-0.01499719j, -0.00047244-0.062564j  ],\n",
       "                           ...,\n",
       "                           [ 0.016186  -0.07071969j,  0.06041606+0.0013908j ,\n",
       "                            -0.00204494-0.05479937j, ..., -0.01206347-0.00953804j,\n",
       "                             0.01387939+0.01142519j,  0.06827804-0.00052374j],\n",
       "                           [-0.03107786-0.00929933j,  0.00197645-0.03761125j,\n",
       "                            -0.06194622+0.01517664j, ..., -0.00675314+0.01405836j,\n",
       "                             0.03603373+0.0897334j ,  0.03137581-0.0233704j ],\n",
       "                           [-0.011542  -0.01339844j,  0.06533881+0.01900501j,\n",
       "                             0.0469201 -0.00905274j, ...,  0.02086875+0.04661913j,\n",
       "                             0.0047786 -0.05948972j,  0.05550821+0.00266234j]]],\n",
       "            \n",
       "            \n",
       "                         [[[-0.00739908-0.04047845j, -0.02520156-0.03820732j,\n",
       "                             0.00987231-0.02073619j, ..., -0.02622228-0.08479555j,\n",
       "                            -0.04966649+0.02516316j,  0.01229815-0.01553866j],\n",
       "                           [-0.01758949+0.02158709j, -0.01277409-0.10311904j,\n",
       "                            -0.02621247+0.05389592j, ..., -0.01685756-0.0646777j ,\n",
       "                             0.02348607+0.06057256j,  0.05774566+0.00925315j],\n",
       "                           [-0.04029479+0.07930255j,  0.07672138-0.03535072j,\n",
       "                            -0.00443778-0.03642204j, ..., -0.04324635-0.03853513j,\n",
       "                             0.00614776-0.04099689j,  0.05948791-0.02770783j],\n",
       "                           ...,\n",
       "                           [-0.03589699-0.00612841j, -0.02478058-0.00411575j,\n",
       "                            -0.00459379-0.03278982j, ..., -0.04113766-0.05248188j,\n",
       "                             0.03270591-0.0756566j ,  0.01303114-0.01168042j],\n",
       "                           [-0.06219921+0.01415236j, -0.02765798+0.07774929j,\n",
       "                            -0.02425202-0.02313663j, ..., -0.05035084-0.0084395j ,\n",
       "                            -0.02181763-0.04293394j,  0.02681843-0.04129121j],\n",
       "                           [-0.00517714-0.02661643j, -0.03150057-0.03964495j,\n",
       "                             0.00137364+0.00567223j, ...,  0.01550008+0.00766186j,\n",
       "                             0.02128117-0.0345283j ,  0.03118763-0.01669058j]],\n",
       "            \n",
       "                          [[-0.00946499-0.08660514j, -0.00741554+0.00021613j,\n",
       "                             0.0289353 -0.01795608j, ...,  0.09245613+0.04843209j,\n",
       "                             0.02914987+0.01718153j, -0.03571832+0.01655532j],\n",
       "                           [-0.01314144+0.03661299j, -0.0042907 +0.00815333j,\n",
       "                             0.0774503 -0.05653615j, ...,  0.04421613-0.10519024j,\n",
       "                            -0.06124237-0.00904844j,  0.01078101+0.0068779j ],\n",
       "                           [ 0.0048596 -0.01800465j,  0.0156912 +0.00577473j,\n",
       "                            -0.00292428+0.04225604j, ..., -0.08956331-0.04478056j,\n",
       "                            -0.09263206+0.03221093j,  0.01671437+0.02368125j],\n",
       "                           ...,\n",
       "                           [ 0.0083968 -0.02651003j, -0.02036333+0.02552295j,\n",
       "                             0.02047267+0.02369934j, ..., -0.05060646-0.00129636j,\n",
       "                            -0.00870138-0.0256406j , -0.03413999-0.01804421j],\n",
       "                           [-0.06533098-0.00271677j,  0.02022287-0.0042271j ,\n",
       "                             0.02356731-0.04821701j, ...,  0.04831822-0.01367759j,\n",
       "                             0.04894182+0.02228088j, -0.03587157+0.01199438j],\n",
       "                           [-0.01778438-0.00802067j,  0.04459663-0.00582603j,\n",
       "                            -0.01332948+0.05345174j, ...,  0.03207416+0.03762383j,\n",
       "                            -0.1089303 -0.04166652j, -0.02089066-0.05098331j]],\n",
       "            \n",
       "                          [[ 0.05843508+0.04764175j,  0.03228656+0.04867017j,\n",
       "                             0.01981429-0.04345887j, ...,  0.02172439-0.02817931j,\n",
       "                            -0.03159406+0.03450636j,  0.08246113-0.02706564j],\n",
       "                           [ 0.01157033-0.08383736j, -0.06092072+0.03643163j,\n",
       "                             0.00610527-0.05490119j, ..., -0.01768595-0.00282318j,\n",
       "                             0.02162451-0.09368527j,  0.00882788-0.03175146j],\n",
       "                           [-0.05830017-0.03318848j, -0.03882695+0.03594168j,\n",
       "                             0.02710397+0.0549146j , ...,  0.02952221-0.0237322j ,\n",
       "                             0.01961783-0.00070744j, -0.01412759-0.04146414j],\n",
       "                           ...,\n",
       "                           [ 0.01186478+0.09163568j,  0.02294204+0.03811735j,\n",
       "                             0.04267477+0.06742877j, ...,  0.04935715-0.03245886j,\n",
       "                             0.07924388+0.01998911j,  0.01976891-0.02808864j],\n",
       "                           [-0.02669167+0.04828747j, -0.02589402+0.07146578j,\n",
       "                            -0.07527087+0.03047658j, ...,  0.00496054+0.03608778j,\n",
       "                             0.05745455-0.04701955j,  0.03763792-0.01221029j],\n",
       "                           [ 0.02064725+0.05138867j, -0.02938535-0.04277956j,\n",
       "                            -0.04810987-0.00547527j, ..., -0.00701361-0.00058744j,\n",
       "                             0.01693402-0.0743197j , -0.07966983+0.03092814j]]],\n",
       "            \n",
       "            \n",
       "                         [[[ 0.04113882-0.03784276j, -0.01148897-0.0707882j ,\n",
       "                             0.01196436-0.00753912j, ...,  0.03112344-0.05441579j,\n",
       "                            -0.07291996-0.02319837j,  0.02437895+0.00765043j],\n",
       "                           [ 0.01126438-0.0095442j ,  0.00169729-0.04505463j,\n",
       "                             0.07805749+0.00371271j, ...,  0.00101987-0.03423512j,\n",
       "                            -0.05846393-0.02676198j,  0.02831571-0.05209141j],\n",
       "                           [-0.054502  -0.0231922j ,  0.01743814+0.05369597j,\n",
       "                             0.01255402+0.07779525j, ...,  0.04790648+0.0033377j ,\n",
       "                             0.03458898+0.05421688j,  0.0362873 +0.01275647j],\n",
       "                           ...,\n",
       "                           [-0.03565944-0.02161789j,  0.00853516-0.05374192j,\n",
       "                            -0.03886983+0.00722586j, ...,  0.03369293+0.01671713j,\n",
       "                            -0.0490187 -0.01446194j,  0.01034379+0.01442978j],\n",
       "                           [ 0.02522832-0.10477759j, -0.05630907+0.07105921j,\n",
       "                             0.04496324-0.01486476j, ..., -0.03454873-0.08375008j,\n",
       "                            -0.02838003+0.03890059j, -0.04037192+0.00747424j],\n",
       "                           [-0.05620413-0.03434191j, -0.04748479-0.04773013j,\n",
       "                            -0.017828  +0.04835415j, ...,  0.01361079+0.03890276j,\n",
       "                             0.03734003-0.02042901j,  0.00948691-0.02124074j]],\n",
       "            \n",
       "                          [[-0.04030041-0.03677586j, -0.02819786-0.05125115j,\n",
       "                            -0.06318927-0.04405806j, ...,  0.10100383+0.04800159j,\n",
       "                             0.07091224+0.01199588j,  0.00242267+0.03284426j],\n",
       "                           [-0.066937  -0.0228253j , -0.06959972-0.08197798j,\n",
       "                            -0.04253063-0.03614676j, ...,  0.10058032-0.03387716j,\n",
       "                             0.01937906+0.00996431j,  0.02878125+0.04783472j],\n",
       "                           [-0.00296126-0.03153914j, -0.07961685-0.02319021j,\n",
       "                            -0.02553554+0.00676499j, ...,  0.0395816 -0.04295862j,\n",
       "                            -0.01557588+0.01507385j, -0.02654259-0.0477337j ],\n",
       "                           ...,\n",
       "                           [-0.0249464 -0.03142358j,  0.04703369-0.04344802j,\n",
       "                            -0.05044467-0.00527502j, ..., -0.0286504 +0.04424941j,\n",
       "                            -0.02464607-0.02085706j, -0.09259038+0.04602525j],\n",
       "                           [ 0.03526206-0.04862034j, -0.09416284+0.04150506j,\n",
       "                            -0.01463136-0.00114503j, ..., -0.01664403+0.04308569j,\n",
       "                             0.0496546 +0.04739707j,  0.01350764-0.07252463j],\n",
       "                           [-0.08748839+0.02544408j,  0.00582809-0.00328244j,\n",
       "                             0.06516945-0.04414672j, ...,  0.01654481+0.02002647j,\n",
       "                            -0.05192694-0.02710955j,  0.00883981-0.03566636j]],\n",
       "            \n",
       "                          [[ 0.00048873-0.0933818j ,  0.03794024-0.00588173j,\n",
       "                             0.04474441-0.03003041j, ..., -0.0022995 -0.04623683j,\n",
       "                             0.00858391-0.04962933j,  0.00317031-0.06188686j],\n",
       "                           [ 0.02493256+0.0345505j , -0.00470002-0.00216242j,\n",
       "                            -0.00129293-0.07741508j, ...,  0.01333852+0.06177928j,\n",
       "                             0.04119208+0.0809644j , -0.03793275+0.01421186j],\n",
       "                           [ 0.06340757+0.0062491j ,  0.0639681 -0.05725472j,\n",
       "                            -0.02770126+0.04822938j, ...,  0.00051732+0.05953637j,\n",
       "                             0.02068629-0.0514216j ,  0.03805289-0.02938008j],\n",
       "                           ...,\n",
       "                           [ 0.01266815-0.02810366j, -0.01640012-0.07698874j,\n",
       "                            -0.05513754-0.00315611j, ...,  0.00275977+0.04407627j,\n",
       "                             0.06014267-0.00657596j, -0.03849079-0.02687252j],\n",
       "                           [ 0.0222428 +0.01561745j,  0.04239855-0.02679922j,\n",
       "                            -0.02382878-0.01774163j, ...,  0.00654835-0.00703072j,\n",
       "                             0.08594643-0.00457872j,  0.00991222-0.07496342j],\n",
       "                           [ 0.03762558+0.09069966j,  0.01104344+0.02443344j,\n",
       "                             0.02345184+0.0079308j , ..., -0.03765092+0.09974944j,\n",
       "                             0.04195664+0.00808922j, -0.00711321-0.01335978j]]]],            dtype=complex128),\n",
       "            bias: DeviceArray([0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
       "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
       "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
       "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
       "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
       "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
       "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
       "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
       "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
       "                         0.+0.j], dtype=complex128),\n",
       "        },\n",
       "        Dense_0: {\n",
       "            kernel: DeviceArray([[-0.00043805+0.0216163j , -0.00330651-0.0051889j ,\n",
       "                          -0.00094935+0.00525378j, ...,  0.00634915-0.0134044j ,\n",
       "                          -0.0198508 -0.01853866j, -0.00043443+0.00892607j],\n",
       "                         [-0.00419066-0.00551281j, -0.01392447+0.01769329j,\n",
       "                           0.01735105+0.01430123j, ...,  0.01695513+0.01357991j,\n",
       "                          -0.0093178 -0.00275035j, -0.01058093-0.00699949j],\n",
       "                         [-0.0090597 -0.00483106j,  0.01755417+0.01171472j,\n",
       "                           0.01126804+0.00257518j, ...,  0.00920114-0.00385838j,\n",
       "                           0.0021842 -0.00900351j,  0.00871633+0.0215766j ],\n",
       "                         ...,\n",
       "                         [ 0.00225832-0.01247211j,  0.00049717-0.01971836j,\n",
       "                          -0.01762597-0.01134032j, ...,  0.00720588-0.02386846j,\n",
       "                          -0.00297984+0.01575289j,  0.00250164-0.01518775j],\n",
       "                         [ 0.01647148-0.00030906j, -0.00611536-0.00263544j,\n",
       "                          -0.03235728+0.00461409j, ...,  0.00513343-0.00736959j,\n",
       "                          -0.01690031-0.01394483j, -0.00250813-0.02787838j],\n",
       "                         [-0.00207475+0.01566063j,  0.00049216+0.00182149j,\n",
       "                           0.00800676-0.00856403j, ...,  0.00403975-0.021287j  ,\n",
       "                          -0.01319485-0.02276621j,  0.00180646+0.00672091j]],            dtype=complex128),\n",
       "            bias: DeviceArray([0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
       "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
       "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
       "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
       "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
       "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
       "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
       "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
       "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
       "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
       "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
       "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
       "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
       "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
       "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
       "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
       "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
       "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
       "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
       "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
       "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
       "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
       "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
       "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
       "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
       "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
       "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
       "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
       "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
       "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
       "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
       "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
       "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
       "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
       "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
       "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
       "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j], dtype=complex128),\n",
       "        },\n",
       "        Dense_1: {\n",
       "            kernel: DeviceArray([[ 0.02571171+0.00667496j,  0.01818865+0.03476768j,\n",
       "                          -0.02975401-0.01123561j, ...,  0.01867569-0.00573767j,\n",
       "                          -0.04099714-0.03560352j,  0.00483609+0.02600795j],\n",
       "                         [ 0.03800599-0.06318171j, -0.03253668+0.06502207j,\n",
       "                           0.02504367+0.01371072j, ...,  0.0076168 -0.00794348j,\n",
       "                          -0.05459801-0.02422021j, -0.03069208-0.07211422j],\n",
       "                         [-0.0138114 -0.01123484j, -0.00514056+0.03335077j,\n",
       "                          -0.03644072+0.04274664j, ..., -0.05531259-0.02518446j,\n",
       "                           0.00789196-0.02903889j,  0.03195075-0.01573669j],\n",
       "                         ...,\n",
       "                         [ 0.00119587-0.05519684j,  0.01959933-0.00424355j,\n",
       "                          -0.08662269+0.01614252j, ..., -0.07184621+0.07310146j,\n",
       "                           0.02064405-0.06809902j,  0.04506467-0.01749488j],\n",
       "                         [ 0.01379107+0.00911554j, -0.00883593+0.06330193j,\n",
       "                          -0.00887568-0.05684631j, ...,  0.07547394+0.05109712j,\n",
       "                           0.09561358+0.01229632j,  0.00898184-0.05866284j],\n",
       "                         [-0.06151762-0.02327297j,  0.02239452-0.01561381j,\n",
       "                          -0.03008847+0.01177773j, ...,  0.00628201+0.01089115j,\n",
       "                          -0.00349766+0.03550121j, -0.00781439+0.04114626j]],            dtype=complex128),\n",
       "            bias: DeviceArray([0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
       "                         0.+0.j, 0.+0.j, 0.+0.j], dtype=complex128),\n",
       "        },\n",
       "    },\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7604bf44-3b6e-4550-93bf-af5253a50364",
   "metadata": {
    "id": "7604bf44-3b6e-4550-93bf-af5253a50364"
   },
   "source": [
    "we can inspect the parameters `pars`:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ebdbb9-8e06-4620-89f8-572f752ff73e",
   "metadata": {
    "id": "11ebdbb9-8e06-4620-89f8-572f752ff73e"
   },
   "source": [
    "## 3 - Writing the loss function\n",
    "\n",
    "We now want to take as a loss function the distance between the _predicted_ probability given by the model $q_W^{(i)}(x)$ and the actualy probabilith $p^{(i)}(x)$.\n",
    "\n",
    "The actual probability is a delta function: it is zero for every label except for the correct one, for which it is 1.\n",
    "\n",
    "To perform this, we can use one-hot encoding, which takes an integer value in $i\\in[0..K]$ and returns a vector in $R^K$ where only the i-th component is 1 and the other are zero: $v_j = \\delta_{i,j}$.\n",
    "\n",
    "See the examples below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d168c699-dbc5-4f84-9f1f-40511e35050f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d168c699-dbc5-4f84-9f1f-40511e35050f",
    "outputId": "bcbb1f8e-baaf-4a45-87b3-8d808f670541"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 becomes: [1. 0. 0. 0. 0.]\n",
      "1 becomes: [0. 1. 0. 0. 0.]\n",
      "2 becomes: [0. 0. 1. 0. 0.]\n",
      "3 becomes: [0. 0. 0. 1. 0.]\n",
      "4 becomes: [0. 0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(f\"{i} becomes: {jax.nn.one_hot(i, 5)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c72691d-9a4e-4826-a042-67b0aaa3238e",
   "metadata": {
    "id": "1c72691d-9a4e-4826-a042-67b0aaa3238e"
   },
   "source": [
    "For the loss function, i'll draw from my vast knowledge of loss functions (aka: [here](https://optax.readthedocs.io/en/latest/api.html)) and choose `optax.softmax_cross_entropy`.\n",
    "\n",
    "However, for the sake of completeness, i'll write it down here by hand.\n",
    "\n",
    "`?optax.softmax_cross_entropy`\n",
    "> Computes the softmax cross entropy between sets of logits and labels.\n",
    ">\n",
    ">Measures the probability error in discrete classification tasks in which\n",
    ">the classes are mutually exclusive (each entry is in exactly one class).\n",
    ">For example, each CIFAR-10 image is labeled with one and only one label:\n",
    ">an image can be a dog or a truck, but not both.\n",
    ">\n",
    ">References:\n",
    "> [Goodfellow et al, 2016](http://www.deeplearningbook.org/contents/prob.html)\n",
    ">\n",
    ">Args:\n",
    ">\n",
    ">  logits: unnormalized log probabilities.\n",
    ">\n",
    ">  labels: a valid probability distribution (non-negative, sum to 1), e.g a\n",
    ">    one hot encoding of which class is the correct one for each input.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b7a0b6-6157-4bf5-a6a0-39888bebe46b",
   "metadata": {
    "id": "a2b7a0b6-6157-4bf5-a6a0-39888bebe46b"
   },
   "source": [
    "The cross entropy between an approximate distribution $P_W(x)$ and a target distribution $Q(x)$ is defined as \n",
    "\n",
    "$$\n",
    "\\mathcal{L}(W) = - \\langle log P_W(x) \\rangle_{x \\approx Q(x)} = - \\sum_{x \\approx Q(x)} log P_W(x)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6b8b08",
   "metadata": {},
   "source": [
    "***NOTE***: why is cross-entropy such a good loss function (much better than the sum of squared residuals)?\n",
    "=> because the slope (tangent line) for cross entropy for a bad prediction will be relatively large, compared to the derivative for that same bad prediction with squared residuals. This helps us when performing gradient descent!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4112499-6b6f-445e-bd18-22fd5b0b2a78",
   "metadata": {
    "id": "e4112499-6b6f-445e-bd18-22fd5b0b2a78"
   },
   "outputs": [],
   "source": [
    "# The loss function that we will use\n",
    "def cross_entropy(*, logits, labels):\n",
    "    one_hot_labels = jax.nn.one_hot(labels, num_classes=10)\n",
    "    return -jnp.mean(jnp.sum(one_hot_labels * logits, axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "Hx-ZQzpLZMj4",
   "metadata": {
    "id": "Hx-ZQzpLZMj4"
   },
   "outputs": [],
   "source": [
    "dropout_rng, init_dropout = jax.random.split(jax.random.PRNGKey(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e90668ed-0090-446a-81d3-4f6e1763b2e2",
   "metadata": {
    "id": "e90668ed-0090-446a-81d3-4f6e1763b2e2"
   },
   "outputs": [],
   "source": [
    "def loss_fn(params, dropout_rng, images, labels):\n",
    "    \"\"\"\n",
    "    Loss function minimised during training of the model.\n",
    "    \"\"\"\n",
    "    # compute the output of the model, which gives the \n",
    "    # log-probability distribution over the possible classes (0...9)\n",
    "    logits = model.apply(params, images, rngs={'dropout' : dropout_rng})\n",
    "    # feed it to the cross_entropy\n",
    "    return cross_entropy(logits=logits, labels=labels)\n",
    "\n",
    "def compute_metrics(*, logits, labels):\n",
    "    \"\"\"\n",
    "    Compute metrics of the model during training.\n",
    "    \n",
    "    Returns the loss and the accuracy.\n",
    "    \"\"\"\n",
    "    loss = cross_entropy(logits=logits, labels=labels)\n",
    "    accuracy = jnp.mean(jnp.argmax(logits, -1) == labels)\n",
    "    metrics = {\n",
    "      'loss': loss,\n",
    "      'accuracy': accuracy,\n",
    "    }\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0ff54a-3d6a-42e7-bdf3-23a9b0d899fd",
   "metadata": {
    "id": "ff0ff54a-3d6a-42e7-bdf3-23a9b0d899fd"
   },
   "source": [
    "## 4 - Create the setup and training loop\n",
    "\n",
    "We need to define some functions to create the initial state and we need to define a function to execute one training step, and the whole training loop.\n",
    "\n",
    "For the optimiser, we use optimisers defined in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "50082ccb-9022-496a-8898-f2b645116347",
   "metadata": {
    "id": "50082ccb-9022-496a-8898-f2b645116347"
   },
   "outputs": [],
   "source": [
    "import optax\n",
    "from flax.training import train_state  # Useful dataclass to keep train state\n",
    "\n",
    "def create_train_state(rng, optimiser, dropout_rng):\n",
    "    \"\"\"Creates initial `TrainState`, holding the current parameters, state of the\n",
    "    optimiser and other metadata.\n",
    "    \"\"\"\n",
    "    # Construct the model parameters\n",
    "    params = model.init({'params' : rng, 'dropout' : dropout_rng}, jnp.ones([1, 28, 28, 1]))\n",
    "        \n",
    "    # Package all those informations in the model state\n",
    "    return train_state.TrainState.create(\n",
    "        apply_fn=model.apply, params=params, tx=optimiser)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4d0ec7de-f082-4276-96e6-86c59712ba69",
   "metadata": {
    "id": "4d0ec7de-f082-4276-96e6-86c59712ba69"
   },
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def eval_metrics(params, batch, dropout_rng):\n",
    "    \"\"\"\n",
    "    This function evaluates the metrics without training the model.\n",
    "    \n",
    "    Used to check the performance of the network on training and test datasets.\n",
    "    \"\"\"\n",
    "    logits = model.apply(params, batch['image'], rngs={'dropout' : dropout_rng})\n",
    "    return compute_metrics(logits=logits, labels=batch['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5f6b6254-da8a-4bd5-ad56-15b13a3c2bd2",
   "metadata": {
    "id": "5f6b6254-da8a-4bd5-ad56-15b13a3c2bd2"
   },
   "outputs": [],
   "source": [
    "# Partial is handy as it can be used to 'fix' some arguments to a function.\n",
    "# so partial(f, x)(y) == f(x,y)\n",
    "from functools import partial\n",
    "\n",
    "@jax.jit\n",
    "def train_step(state, batch, dropout_rng):\n",
    "    \"\"\"\n",
    "    Train for a single step.\n",
    "    \n",
    "    The input images `batch` should not be too large, otherwise we will run\n",
    "    out of memory. Therefore the input should be 'batched', meaning should be\n",
    "    separated into small blocks of ~hundreds (instead of tens of thousands)\n",
    "    iamges.\n",
    "    \"\"\"\n",
    "    # Fix some arguments to the loss function (so that the only 'free' parameter is\n",
    "    # the parameters of the network.\n",
    "    _loss_fn = partial(loss_fn, dropout_rng = dropout_rng, images=batch['image'], labels=batch['label'])\n",
    "    # construct the function returning the loss value and gradient.\n",
    "    val_grad_fn = jax.value_and_grad(_loss_fn)\n",
    "    # compute loss and gradient\n",
    "    loss, grads = val_grad_fn(state.params)\n",
    "\n",
    "    # NEW: MANUALLY CONJUGATE THE GRADIENTS!!!! THANKS DIAN <3\n",
    "    grads = jax.tree_map(lambda x: x.conj(), grads) # <- Add this!\n",
    "\n",
    "    # update the state parameters with the new gradients\n",
    "    # objects are immutable so the output of this function is a different\n",
    "    # object than the starting one.\n",
    "    state = state.apply_gradients(grads=grads)\n",
    "    \n",
    "    # Evaluate the network again to get the log-probability distribution\n",
    "    # over the batch images\n",
    "    metrics = eval_metrics(state.params, batch, dropout_rng)\n",
    "    \n",
    "    return state, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e2f17cf0-198d-4d57-88d9-de60e6e76492",
   "metadata": {
    "id": "e2f17cf0-198d-4d57-88d9-de60e6e76492"
   },
   "outputs": [],
   "source": [
    "def train_epoch(state, train_ds, batch_size, epoch, rng, dropout_rng, *, max_steps=None):\n",
    "    \"\"\"Train for a single `epoch`.\n",
    "    \n",
    "    And epoch is composed of several steps, where every step is taken by updating\n",
    "    the network parameters with a small mini-batch.\n",
    "    \"\"\"\n",
    "    \n",
    "    # total number of training images\n",
    "    train_ds_size = len(train_ds['image'])\n",
    "    \n",
    "    # Compute how many steps are present in this epoch.\n",
    "    # In one epoch we want to go through the whole dataset.\n",
    "    steps_per_epoch = train_ds_size // batch_size\n",
    "\n",
    "    # Truncate the number of steps (used to speed up training)\n",
    "    # Sometimes we might want not to go through the whole dataset\n",
    "    # in an epoch.\n",
    "    if max_steps is not None:\n",
    "        steps_per_epoch = min(steps_per_epoch, max_steps)\n",
    "\n",
    "    # generate a random permutation of the indices to shuffle the training\n",
    "    # dataset, and reshape it to a set of batches.\n",
    "    perms = jax.random.permutation(rng, train_ds_size)\n",
    "    perms = perms[:steps_per_epoch * batch_size]\n",
    "    perms = perms.reshape((steps_per_epoch, batch_size))\n",
    "    \n",
    "    # execute the training step for every mini-batch\n",
    "    batch_metrics = []\n",
    "    for perm in perms:\n",
    "        batch = {k: v[perm, ...] for k, v in train_ds.items()}\n",
    "        state, metrics = train_step(state, batch, dropout_rng)\n",
    "        batch_metrics.append(metrics)\n",
    "\n",
    "    # compute mean of metrics across each batch in epoch.\n",
    "    batch_metrics_np = jax.device_get(batch_metrics)\n",
    "    epoch_metrics_np = {\n",
    "        k: np.mean([metrics[k] for metrics in batch_metrics_np])\n",
    "            for k in batch_metrics_np[0]}\n",
    "\n",
    "    return state, epoch_metrics_np\n",
    "\n",
    "\n",
    "def evaluate_model(params, test_ds, dropout_rng):\n",
    "    \"\"\"\n",
    "    evaluate the performance of the model on the test dataset\n",
    "    \"\"\"\n",
    "    metrics = eval_metrics(params, test_ds, dropout_rng)\n",
    "    metrics = jax.device_get(metrics)\n",
    "    summary = jax.tree_map(lambda x: x.item(), metrics)\n",
    "    return summary['loss'], summary['accuracy']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1db647-2349-46d8-8f6f-8bebedf73872",
   "metadata": {
    "id": "ed1db647-2349-46d8-8f6f-8bebedf73872"
   },
   "source": [
    "# 5 - Running the optimisation\n",
    "\n",
    "We will now finally run the optimisation.  Below we will define all the required HyperParameters.\n",
    "\n",
    "For the optimiser, we pick one from the [optax](https://optax.readthedocs.io) package, which is very comprehensive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d1123ddd-9083-4122-b47d-07513797aad3",
   "metadata": {
    "id": "d1123ddd-9083-4122-b47d-07513797aad3"
   },
   "outputs": [],
   "source": [
    "# Definition of optimiser HyperParameters\n",
    "\n",
    "learning_rate = 0.01\n",
    "\"\"\"\n",
    "Standard SGD step size\n",
    "\"\"\"\n",
    "momentum = 0.9\n",
    "\"\"\"\n",
    "Amount of memntum. The maximum effective learning rate will be\n",
    "$ learning_rate * momentum/(1-momentum)$\n",
    "\"\"\"\n",
    "\n",
    "# Construct the optimiser\n",
    "# we use optimisers from the optax package which is a very comprehensive\n",
    "# optimiser library\n",
    "optimiser = optax.sgd(learning_rate, momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "afae251b-a760-4156-ae09-51e4476d769d",
   "metadata": {
    "id": "afae251b-a760-4156-ae09-51e4476d769d"
   },
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "\n",
    "batch_size = 32\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "\n",
    "max_steps = 200\n",
    "\"\"\"\n",
    "Cutoff to the number of steps (minibatches) in an epoch\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6e7263bc-b1f0-4a71-8b2a-ff19daf8257b",
   "metadata": {
    "id": "6e7263bc-b1f0-4a71-8b2a-ff19daf8257b"
   },
   "outputs": [],
   "source": [
    "# Split the rng to get two keys, one to 'shuffle' the dataset at every iteration,\n",
    "# and one to initialise the network\n",
    "rng, init_rng = jax.random.split(jax.random.PRNGKey(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6a077215-b821-45cf-8747-cd7154f4351a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 396,
     "referenced_widgets": [
      "ca9e12c942d44da198e547847a9858e8",
      "7d8e72ccff7a4e879b6337b7c5d7c661",
      "697375ac698e4bc8a872c12933b4a522",
      "dde09fc3f18f4b1c91fb42f7111e0500",
      "acf2fc1089844f0c9e7790b157c892d6",
      "9b160d0b614c4b0eb031b800bfd12aa4",
      "5bd5b0f8ff3441c1be0e851acee6ecde",
      "8f1a2792ffd04a798b7bd3ab9ccc8f8b",
      "6ac9a75e9e694f90b0e1c0a9c4ac1c3c",
      "2e6b61e193674b23b3f74ac232abbceb",
      "eef312eb689a435d94f40232015fd293"
     ]
    },
    "id": "6a077215-b821-45cf-8747-cd7154f4351a",
    "outputId": "b983e8dd-3ab4-4057-9b16-95c9cc0d81c1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [03:08<28:20, 188.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 1, loss: 0.4605, accuracy: 83.33\n",
      " test epoch: 1, loss: 0.39, accuracy: 85.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [06:18<25:16, 189.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 2, loss: 0.2970, accuracy: 89.21\n",
      " test epoch: 2, loss: 0.33, accuracy: 88.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [08:57<20:28, 175.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 3, loss: 0.2546, accuracy: 90.70\n",
      " test epoch: 3, loss: 0.29, accuracy: 89.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [11:37<16:56, 169.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 4, loss: 0.2278, accuracy: 91.65\n",
      " test epoch: 4, loss: 0.26, accuracy: 90.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [14:08<13:33, 162.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 5, loss: 0.2073, accuracy: 92.52\n",
      " test epoch: 5, loss: 0.26, accuracy: 90.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [16:39<10:34, 158.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 6, loss: 0.1864, accuracy: 93.11\n",
      " test epoch: 6, loss: 0.25, accuracy: 91.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [19:08<07:46, 155.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 7, loss: 0.1692, accuracy: 93.80\n",
      " test epoch: 7, loss: 0.25, accuracy: 91.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [21:27<05:00, 150.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 8, loss: 0.1534, accuracy: 94.39\n",
      " test epoch: 8, loss: 0.25, accuracy: 91.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [23:53<02:28, 148.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 9, loss: 0.1432, accuracy: 94.75\n",
      " test epoch: 9, loss: 0.26, accuracy: 91.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [26:24<00:00, 158.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 10, loss: 0.1313, accuracy: 95.19\n",
      " test epoch: 10, loss: 0.25, accuracy: 91.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Import the TQDM progress bar module using automatic notebook detection\n",
    "# Otherwise it would not work..\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "state = create_train_state(init_rng, optimiser, init_dropout)\n",
    "\n",
    "metrics = {\"test_loss\" : [], \"test_accuracy\": [], \"train_loss\":[], \"train_accuracy\":[]}\n",
    "\n",
    "with tqdm(range(1, num_epochs + 1)) as pbar:\n",
    "    for epoch in pbar:\n",
    "        # Use a separate PRNG key to permute image data during shuffling\n",
    "        rng, input_rng = jax.random.split(rng)\n",
    "        dropout_rng, _ = jax.random.split(dropout_rng)\n",
    "        # Run an optimization step over a training batch\n",
    "        state, train_metrics = train_epoch(state, train_ds, batch_size, epoch, input_rng, dropout_rng)\n",
    "        \n",
    "        # Evaluate on the test set after each training epoch\n",
    "        test_loss, test_accuracy = evaluate_model(state.params, test_ds, dropout_rng)\n",
    "        pbar.write('train epoch: %d, loss: %.4f, accuracy: %.2f' % (epoch, train_metrics['loss'], train_metrics['accuracy'] * 100))\n",
    "        pbar.write(' test epoch: %d, loss: %.2f, accuracy: %.2f' % (epoch, test_loss, test_accuracy * 100))\n",
    "\n",
    "        # save data\n",
    "        metrics[\"train_loss\"].append(train_metrics[\"loss\"])\n",
    "        metrics[\"train_accuracy\"].append(train_metrics[\"accuracy\"])\n",
    "        metrics[\"test_loss\"].append(test_loss)\n",
    "        metrics[\"test_accuracy\"].append(test_accuracy)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3489436-f20c-4e1b-8d2c-05ac86769fc0",
   "metadata": {
    "id": "d3489436-f20c-4e1b-8d2c-05ac86769fc0"
   },
   "source": [
    "We now want to check the performance of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aefca0cb-80ed-43df-84de-1b4073a84d54",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aefca0cb-80ed-43df-84de-1b4073a84d54",
    "outputId": "06a49221-82b1-45fb-9524-1c320e12284f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Accuracy')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(1,2, figsize=(12,3))\n",
    "\n",
    "axs[0].plot(metrics[\"train_loss\"], label=\"train\")\n",
    "axs[0].plot(metrics[\"test_loss\"], label=\"test\")\n",
    "axs[0].legend()\n",
    "axs[0].set_xlabel(\"Epoch #\")\n",
    "axs[0].set_ylabel(\"Loss\")\n",
    "\n",
    "\n",
    "axs[1].plot(metrics[\"train_accuracy\"], label=\"train\")\n",
    "axs[1].plot(metrics[\"test_accuracy\"], label=\"test\")\n",
    "axs[1].legend()\n",
    "axs[1].set_xlabel(\"Epoch #\")\n",
    "axs[1].set_ylabel(\"Accuracy\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copie de Copie de 2a-mnist.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "af2da5cc5270e94f5935e371be818e4bec70253d0f779505a7b15694dfa8a491"
  },
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "ml_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "04701b94470e4411b492e05f32420185": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2e6b61e193674b23b3f74ac232abbceb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "320532e08f5549aca2ef73d7eaa1b355": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "32c1a0067c3a4e7fba9065e92bdbc018": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_320532e08f5549aca2ef73d7eaa1b355",
      "placeholder": "​",
      "style": "IPY_MODEL_ace16b3606ad493aab790446a3319436",
      "value": " 4/4 [00:00&lt;00:00,  6.58 file/s]"
     }
    },
    "55e80ba5b1cf432a9fb796a67a3f78b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5bd5b0f8ff3441c1be0e851acee6ecde": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "697375ac698e4bc8a872c12933b4a522": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5bd5b0f8ff3441c1be0e851acee6ecde",
      "placeholder": "​",
      "style": "IPY_MODEL_9b160d0b614c4b0eb031b800bfd12aa4",
      "value": "100%"
     }
    },
    "6ac9a75e9e694f90b0e1c0a9c4ac1c3c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "78c429eff6024aa2a512b15e9b8e5e9d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7d8e72ccff7a4e879b6337b7c5d7c661": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "891bacd221794bbfa89a2f02dbdee926": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_91384fa0fe154c09837d63ce7c101eae",
      "max": 4,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_55e80ba5b1cf432a9fb796a67a3f78b9",
      "value": 4
     }
    },
    "8f1a2792ffd04a798b7bd3ab9ccc8f8b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "91384fa0fe154c09837d63ce7c101eae": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9b160d0b614c4b0eb031b800bfd12aa4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ace16b3606ad493aab790446a3319436": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "acf2fc1089844f0c9e7790b157c892d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_eef312eb689a435d94f40232015fd293",
      "placeholder": "​",
      "style": "IPY_MODEL_2e6b61e193674b23b3f74ac232abbceb",
      "value": " 10/10 [05:00&lt;00:00, 28.54s/it]"
     }
    },
    "ca9e12c942d44da198e547847a9858e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_697375ac698e4bc8a872c12933b4a522",
       "IPY_MODEL_dde09fc3f18f4b1c91fb42f7111e0500",
       "IPY_MODEL_acf2fc1089844f0c9e7790b157c892d6"
      ],
      "layout": "IPY_MODEL_7d8e72ccff7a4e879b6337b7c5d7c661"
     }
    },
    "d7aa4fb804ea4a73996663c5d0822eb2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dd1bc9bdf2a84c17be8de44ceb04d62f",
      "placeholder": "​",
      "style": "IPY_MODEL_78c429eff6024aa2a512b15e9b8e5e9d",
      "value": "Dl Completed...: 100%"
     }
    },
    "dd1bc9bdf2a84c17be8de44ceb04d62f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dde09fc3f18f4b1c91fb42f7111e0500": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6ac9a75e9e694f90b0e1c0a9c4ac1c3c",
      "max": 10,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8f1a2792ffd04a798b7bd3ab9ccc8f8b",
      "value": 10
     }
    },
    "eef312eb689a435d94f40232015fd293": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fdbbfa9dd9274ac5b5122eb70e8bd166": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d7aa4fb804ea4a73996663c5d0822eb2",
       "IPY_MODEL_891bacd221794bbfa89a2f02dbdee926",
       "IPY_MODEL_32c1a0067c3a4e7fba9065e92bdbc018"
      ],
      "layout": "IPY_MODEL_04701b94470e4411b492e05f32420185"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
