{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "6387de74-7f19-446c-9c10-3d201a270a87",
      "metadata": {
        "id": "6387de74-7f19-446c-9c10-3d201a270a87"
      },
      "source": [
        "# Introduction to Deep Learning\n",
        "\n",
        "### Hands-on 2a: MNIST\n",
        "Filippo Vicentini and Giuseppe Carleo\n",
        "\n",
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/PhilipVinc/IntroDeepLearning/blob/master/2a-mnist.ipynb) \n",
        "\n",
        "\n",
        "The objective of this hands-on is to write and optimise an image-classifier that identifies handwritten digits.\n",
        "\n",
        "We will use for this the [MNIST dataset of handwritten digits](http://yann.lecun.com/exdb/mnist/)\n",
        "\n",
        "![title](https://github.com/PhilipVinc/IntroDeepLearning/blob/master/images/mnist.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e558598f-2027-45fc-8b92-b8e8ae74215e",
      "metadata": {
        "id": "e558598f-2027-45fc-8b92-b8e8ae74215e"
      },
      "source": [
        "## 0 - Install Requirements\n",
        "\n",
        "For this example notebook we will need jax+flax+optax for the machine-learning part.\n",
        "\n",
        "For the dataset, instead, we will be using `tensorflow_datasets`, which is a submodule of `tensorflow` that makes it easy to download and load into memory large datasets (such as MNIST and many others).\n",
        "\n",
        "If you are running notebook locally, you need to also install `tensorflow` to make `tensorflow_datasets` work."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d7895a56-6b30-49bc-b07e-1fe5a6a00b09",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7895a56-6b30-49bc-b07e-1fe5a6a00b09",
        "outputId": "cbc148e3-bf63-467f-f170-e6f34ecd43c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow_datasets in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (4.4.0)\n",
            "Requirement already satisfied: flax in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (0.3.6)\n",
            "Requirement already satisfied: jax in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (0.2.25)\n",
            "Requirement already satisfied: optax in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (0.1.0)\n",
            "Requirement already satisfied: tqdm in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (4.62.3)\n",
            "Requirement already satisfied: netket in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (3.2)\n",
            "Requirement already satisfied: imgaug==0.2.6 in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (0.2.6)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from tensorflow_datasets) (21.2.0)\n",
            "Requirement already satisfied: tensorflow-metadata in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from tensorflow_datasets) (1.5.0)\n",
            "Requirement already satisfied: six in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from tensorflow_datasets) (1.16.0)\n",
            "Requirement already satisfied: protobuf>=3.12.2 in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from tensorflow_datasets) (3.19.1)\n",
            "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from tensorflow_datasets) (5.4.0)\n",
            "Requirement already satisfied: absl-py in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from tensorflow_datasets) (1.0.0)\n",
            "Requirement already satisfied: numpy in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from tensorflow_datasets) (1.20.0)\n",
            "Requirement already satisfied: termcolor in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from tensorflow_datasets) (1.1.0)\n",
            "Requirement already satisfied: future in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from tensorflow_datasets) (0.18.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from tensorflow_datasets) (2.26.0)\n",
            "Requirement already satisfied: promise in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from tensorflow_datasets) (2.3)\n",
            "Requirement already satisfied: dill in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from tensorflow_datasets) (0.3.4)\n",
            "Requirement already satisfied: msgpack in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from flax) (1.0.3)\n",
            "Requirement already satisfied: matplotlib in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from flax) (3.4.3)\n",
            "Requirement already satisfied: opt_einsum in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from jax) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.2.1 in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from jax) (1.7.1)\n",
            "Requirement already satisfied: typing_extensions in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from jax) (3.10.0.2)\n",
            "Requirement already satisfied: jaxlib>=0.1.37 in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from optax) (0.1.74)\n",
            "Requirement already satisfied: chex>=0.0.4 in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from optax) (0.1.0)\n",
            "Requirement already satisfied: numba4jax<0.1,>=0.0.1 in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from netket) (0.0.4)\n",
            "Requirement already satisfied: igraph~=0.9.8 in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from netket) (0.9.8)\n",
            "Requirement already satisfied: numba<0.55,>=0.52 in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from netket) (0.54.1)\n",
            "Requirement already satisfied: plum-dispatch~=1.5.1 in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from netket) (1.5.7)\n",
            "Requirement already satisfied: orjson~=3.4 in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from netket) (3.6.4)\n",
            "Requirement already satisfied: scikit-image>=0.11.0 in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from imgaug==0.2.6) (0.19.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from tensorflow-metadata->tensorflow_datasets) (1.53.0)\n",
            "Requirement already satisfied: zipp>=3.1.0; python_version < \"3.10\" in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from importlib-resources; python_version < \"3.9\"->tensorflow_datasets) (3.6.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from requests>=2.19.0->tensorflow_datasets) (2.0.8)\n",
            "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from requests>=2.19.0->tensorflow_datasets) (3.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from requests>=2.19.0->tensorflow_datasets) (2021.10.8)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from requests>=2.19.0->tensorflow_datasets) (1.26.7)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from matplotlib->flax) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from matplotlib->flax) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from matplotlib->flax) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from matplotlib->flax) (0.10.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from matplotlib->flax) (8.3.2)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from jaxlib>=0.1.37->optax) (2.0)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from chex>=0.0.4->optax) (0.11.2)\n",
            "Requirement already satisfied: dm-tree>=0.1.5 in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from chex>=0.0.4->optax) (0.1.6)\n",
            "Requirement already satisfied: cffi>=1.12 in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from numba4jax<0.1,>=0.0.1->netket) (1.14.6)\n",
            "Requirement already satisfied: texttable>=1.6.2 in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from igraph~=0.9.8->netket) (1.6.4)\n",
            "Requirement already satisfied: setuptools in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from numba<0.55,>=0.52->netket) (41.2.0)\n",
            "Requirement already satisfied: llvmlite<0.38,>=0.37.0rc1 in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from numba<0.55,>=0.52->netket) (0.37.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from scikit-image>=0.11.0->imgaug==0.2.6) (2.6.3)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from scikit-image>=0.11.0->imgaug==0.2.6) (2021.11.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from scikit-image>=0.11.0->imgaug==0.2.6) (21.0)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from scikit-image>=0.11.0->imgaug==0.2.6) (1.2.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from scikit-image>=0.11.0->imgaug==0.2.6) (2.13.1)\n",
            "Requirement already satisfied: pycparser in /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages (from cffi>=1.12->numba4jax<0.1,>=0.0.1->netket) (2.20)\n",
            "\u001b[33mWARNING: You are using pip version 19.2.3, however version 21.3.1 is available.\n",
            "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Requirements\n",
        "!pip install tensorflow_datasets flax jax optax tqdm netket imgaug==0.2.6"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f998ee7-4e9d-4538-b125-5222253ad15b",
      "metadata": {
        "id": "3f998ee7-4e9d-4538-b125-5222253ad15b"
      },
      "source": [
        "### 0.1 - Utility Functions\n",
        "\n",
        "Don't look here. There is nothing interesting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "561535f1-4d9a-4908-bbb7-e63c94d22d47",
      "metadata": {
        "id": "561535f1-4d9a-4908-bbb7-e63c94d22d47"
      },
      "outputs": [],
      "source": [
        "# Utility functions (don't worry. you don't need to understand this one)\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "def show_img(img, ax=None, title=None):\n",
        "  \"\"\"Shows a single image.\n",
        "  \n",
        "  Must be stored as a 3d-tensor where the last dimension is 1 channel (greyscale)\n",
        "  \"\"\"\n",
        "  if ax is None:\n",
        "    ax = plt.gca()\n",
        "  ax.imshow(img[..., 0], cmap='gray')\n",
        "  ax.set_xticks([])\n",
        "  ax.set_yticks([])\n",
        "  if title:\n",
        "    ax.set_title(title)\n",
        "\n",
        "def show_img_grid(imgs, titles):\n",
        "  \"\"\"Shows a grid of images.\"\"\"\n",
        "  n = int(np.ceil(len(imgs)**.5))\n",
        "  _, axs = plt.subplots(n, n, figsize=(3 * n, 3 * n))\n",
        "  for i, (img, title) in enumerate(zip(imgs, titles)):\n",
        "    show_img(img, axs[i // n][i % n], title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "241cfd9e-6a5e-4257-b3b5-2e7bad914a5e",
      "metadata": {
        "id": "241cfd9e-6a5e-4257-b3b5-2e7bad914a5e"
      },
      "outputs": [],
      "source": [
        "# Import \n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55c5988d-c3c3-43d0-abc8-6ceb1c09054d",
      "metadata": {
        "id": "55c5988d-c3c3-43d0-abc8-6ceb1c09054d"
      },
      "source": [
        "## 1 - Setting up the dataset\n",
        "First of all, we need to download the dataset.\n",
        "\n",
        "The MNIST dataset is a standard dataset composed of several 28x28 black/white images representing numbers, and a label corresponding to the number that is represented there."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "90e05be1-0fd8-4562-8251-f8caa0576d3e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292,
          "referenced_widgets": [
            "fdbbfa9dd9274ac5b5122eb70e8bd166",
            "04701b94470e4411b492e05f32420185",
            "d7aa4fb804ea4a73996663c5d0822eb2",
            "891bacd221794bbfa89a2f02dbdee926",
            "32c1a0067c3a4e7fba9065e92bdbc018",
            "78c429eff6024aa2a512b15e9b8e5e9d",
            "dd1bc9bdf2a84c17be8de44ceb04d62f",
            "55e80ba5b1cf432a9fb796a67a3f78b9",
            "91384fa0fe154c09837d63ce7c101eae",
            "ace16b3606ad493aab790446a3319436",
            "320532e08f5549aca2ef73d7eaa1b355"
          ]
        },
        "id": "90e05be1-0fd8-4562-8251-f8caa0576d3e",
        "outputId": "ccc1f310-b66e-4e56-b6f5-e4071f486641"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages/tensorflow_datasets/core/dataset_builder.py:622: get_single_element (from tensorflow.python.data.experimental.ops.get_single_element) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.get_single_element()`.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages/tensorflow_datasets/core/dataset_builder.py:622: get_single_element (from tensorflow.python.data.experimental.ops.get_single_element) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.get_single_element()`.\n"
          ]
        }
      ],
      "source": [
        "# We use Tensorflow datasets to download and import data in a simple numpy-tensor format\n",
        "# It's just handy. You could use anything else.\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "# Specify the dataset we are interested in\n",
        "ds_builder = tfds.builder('mnist')\n",
        "\n",
        "# Download the data\n",
        "ds_builder.download_and_prepare()\n",
        "\n",
        "# Get the whole dataset's train set\n",
        "train_ds = tfds.as_numpy(ds_builder.as_dataset(split='train', batch_size=-1))\n",
        "test_ds = tfds.as_numpy(ds_builder.as_dataset(split='test', batch_size=-1))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a7b5869-071c-4431-b830-fd837948577d",
      "metadata": {
        "id": "0a7b5869-071c-4431-b830-fd837948577d"
      },
      "source": [
        "The dataset is split into two sub-sets: the training dataset that we will use to 'train' our model, and the 'test' dataset, which the model *never sees* during training, but that we use to check that the model performs well.\n",
        "\n",
        "This is to verify that the model does not simply learn _by heart_ the images in the training dataset, but that it actually _learns_ to generalize and works correctly with images that he did not see before.\n",
        "\n",
        "We can inspect the shape of the training dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "dc6521ad-6be7-46ab-9cf4-28d24da2d5d9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dc6521ad-6be7-46ab-9cf4-28d24da2d5d9",
        "outputId": "282065e4-7291-4c45-b3b9-451053a9dbb4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dataset keys: dict_keys(['image', 'label'])\n",
            "The training dataset has shape: (60000, 28, 28, 1) and dtype uint8\n",
            "The test     dataset has shape: (10000, 28, 28, 1) and dtype uint8\n",
            "\n",
            "The training labels have shape: (60000,) and dtype int64\n",
            "The test     labels have shape: (10000,) and dtype int64\n"
          ]
        }
      ],
      "source": [
        "print(\"dataset keys:\", train_ds.keys())\n",
        "print(f\"The training dataset has shape: {train_ds['image'].shape} and dtype {train_ds['image'].dtype}\")\n",
        "print(f\"The test     dataset has shape: {test_ds['image'].shape} and dtype {train_ds['image'].dtype}\")\n",
        "print(\"\")\n",
        "print(f\"The training labels have shape: {train_ds['label'].shape} and dtype {train_ds['label'].dtype}\")\n",
        "print(f\"The test     labels have shape: {test_ds['label'].shape} and dtype {test_ds['label'].dtype}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15665ab5-cb0c-4478-a48e-e0515cbe4fef",
      "metadata": {
        "id": "15665ab5-cb0c-4478-a48e-e0515cbe4fef"
      },
      "source": [
        "We can visualize it to understand it a bit more, using an utility function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "e6146cb7-be9d-4206-8b60-ae27699f0444",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "id": "e6146cb7-be9d-4206-8b60-ae27699f0444",
        "outputId": "d8143b07-dfaf-4b8e-f65c-7fd8dd3f8c42"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 648x648 with 9 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "show_img_grid(\n",
        "    [train_ds['image'][idx] for idx in range(9)],\n",
        "    [f'label={train_ds[\"label\"][idx]}' for idx in range(9)],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "d357d877-89e9-41ea-8301-d5fe22693a90",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d357d877-89e9-41ea-8301-d5fe22693a90",
        "outputId": "2a3adc79-bece-4c38-ec07-aea3f15fdd5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The mean     of the data stored in the images are:  33.318421449829934\n",
            "The variance of the data stored in the images are:  6172.850482291347\n"
          ]
        }
      ],
      "source": [
        "print(\"The mean     of the data stored in the images are: \", np.mean(train_ds['image']))\n",
        "print(\"The variance of the data stored in the images are: \", np.var(train_ds['image']))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73c9f1e8-b449-4589-a826-3dd5771db7ce",
      "metadata": {
        "id": "73c9f1e8-b449-4589-a826-3dd5771db7ce"
      },
      "source": [
        "We have seen that the data is stored in uint8 (an *unsigned* 8-bit integer which can take values from 0 to 255 ).\n",
        "\n",
        "However it is often preferable when working with Neural Networks to work with floating-point values with values around 0 and variance approximately 1. The reasons are 2:\n",
        "\n",
        " - modern CPUs (and to an extent GPUs) are often faster at working with batches (blocks) of floating-point numbers rather than integers [caveats apply]\n",
        " - Many nonlinear functions used in machine-learning have the nonlinear crossover aroud ~0 or ~1/2, so we want our data to be spread around those values\n",
        " - Most research about how to initialize neural-network layers assumes that the input data has mean 0 and variance 1, so to exploit those results we have to rescale our data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "83684f21-5c8e-423d-8c61-9973988fc8cc",
      "metadata": {
        "id": "83684f21-5c8e-423d-8c61-9973988fc8cc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
          ]
        }
      ],
      "source": [
        "# Therefore... let's convert the data!\n",
        "train_ds['image'] = jnp.float32(train_ds['image']) / 255.\n",
        "test_ds['image'] = jnp.float32(test_ds['image']) / 255."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "e5a79b56-21ac-49ec-9485-2590a18a2748",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5a79b56-21ac-49ec-9485-2590a18a2748",
        "outputId": "48e66243-0bc1-4eab-9959-a8d4a6b64121"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The training dataset has shape: (60000, 28, 28, 1) and dtype float32\n",
            "The test     dataset has shape: (10000, 28, 28, 1) and dtype float32\n",
            "The mean     of the data stored in the images are:  0.13066325\n",
            "The variance of the data stored in the images are:  0.09369414\n"
          ]
        }
      ],
      "source": [
        "print(f\"The training dataset has shape: {train_ds['image'].shape} and dtype {train_ds['image'].dtype}\")\n",
        "print(f\"The test     dataset has shape: {test_ds['image'].shape} and dtype {train_ds['image'].dtype}\")\n",
        "\n",
        "print(\"The mean     of the data stored in the images are: \", np.mean(train_ds['image']))\n",
        "print(\"The variance of the data stored in the images are: \", np.var(train_ds['image']))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0bf695fb-0fab-49f3-81fd-9a23fc7ea311",
      "metadata": {
        "id": "0bf695fb-0fab-49f3-81fd-9a23fc7ea311"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "98e56e14-2a4e-4fad-9d47-809ba4b0a354",
      "metadata": {
        "id": "98e56e14-2a4e-4fad-9d47-809ba4b0a354"
      },
      "source": [
        "## 2 - The model (Neural Network)\n",
        "\n",
        "We want now to define the Model.\n",
        "We will use Flax to do that.\n",
        "\n",
        "We want our network to return a probability distribution for the input to correspond to one of several output labels.\n",
        "\n",
        "e.g: if $x$ is an image, then $f : \\mathbb{R}^{28\\times 28}\\rightarrow \\mathbb{R}^{10}$ and $f^{(i)}(x)$ is the probability that the image $x$ represents a $i\\in[0,9]$\n",
        "\n",
        "To make the output of the network a probability distribution, we can use a softmax function, defined as\n",
        "\n",
        "$$\n",
        "\\sigma_i(x) = \\frac{e^{x_i}}{\\sum_i^K e^{x_i} }  \\text{   for  } i\\in [1,K] \\text{ and } x\\in\\mathbb{R}^K\n",
        "$$\n",
        "\n",
        "We want to use a Feedforward network with 2 Dense Layers, relu-nonlinearity and output softmax using Flax.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "***NOTE*** (to myself and whoever else may be interested in this information): we use softmax rather than argmax when training a NN because the argmax wouldn't work with backpropagation (zero derivatives!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "8af5cf83-b3e2-4a1d-b204-73f383952134",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8af5cf83-b3e2-4a1d-b204-73f383952134",
        "outputId": "7463208a-8173-4234-a600-86485bb3d402"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/theresatratzmuller/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages/jax/experimental/stax.py:28: FutureWarning: jax.experimental.stax is deprecated, import jax.example_libraries.stax instead\n",
            "  warnings.warn('jax.experimental.stax is deprecated, '\n"
          ]
        }
      ],
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "\n",
        "# We import flax.linen as nn\n",
        "# The reason is that flax.nn is old and deprecated and will be removed one day\n",
        "import jax\n",
        "import flax\n",
        "\n",
        "# From now on, use netket as nk wherever the original notebook uses flax.linen as nn!\n",
        "import netket as nk\n",
        "import jax.numpy as jnp\n",
        "\n",
        "from jax.experimental import stax"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Original suggestion by Prof Carleo: use modRelu."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "7bf8a1ee-844e-4342-8578-6a0df21cc422",
      "metadata": {
        "id": "7bf8a1ee-844e-4342-8578-6a0df21cc422"
      },
      "outputs": [],
      "source": [
        "def modRelu(z, bias): # relu(|z|+b) * (z / |z|)\n",
        "    norm = jnp.abs(z)\n",
        "    scale = nk.nn.relu(norm + bias) / (norm + 1e-6)\n",
        "    scaled = jax.lax.complex(jnp.real(z)*scale, jnp.imag(z)*scale)\n",
        "    return scaled\n",
        "modRelu=jax.jit(modRelu)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "New suggestion by Dian:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "def complex_relu(z):\n",
        "    return jnp.where(z.real > 0, z, 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "IbeqZDidofc8",
      "metadata": {
        "id": "IbeqZDidofc8"
      },
      "source": [
        " /!\\ You can't use max_pool with complex numbers\n",
        " /!\\ To apply dropout you need to add a parameter to init and apply :\n",
        "\n",
        "logits = model.apply({'params': params}, inputs=inputs, rngs={'dropout': dropout_rng})\n",
        "pars = model.init({'params': jax.random.PRNGKey(seed), 'dropout': jax.random.PRNGKey(seed_dropout)}, sample_input)\n",
        "\n",
        " But be careful, RNG is hell with jax but before wondering about dropout we need to make this simple model work\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "sCGPpmwUkdNb",
      "metadata": {
        "id": "sCGPpmwUkdNb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"\\nclass Model(nk.nn.Module):\\n  n_classes : int = 10\\n  @nk.nn.compact\\n  # Provide a constructor to register a new parameter \\n  # and return its initial value\\n  def __call__(self, x):\\n    dropout_rng = self.make_rng('dropout')\\n    x = nk.nn.Conv(features=32, kernel_size=(3, 3))(x)\\n    x = nk.nn.relu(x)\\n    x = flax.linen.avg_pool(x, window_shape=(2, 2), strides=(2, 2)) # With max pool it diverges. Don't ask me why\\n\\n    \\n\\n    x = nk.nn.Conv(features=64, kernel_size=(3, 3))(x)\\n\\n    x = flax.linen.Dropout(0.5, deterministic=True)(x) #DROPOUT 1\\n\\n    x = nk.nn.relu(x)\\n    x = flax.linen.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\\n\\n    x = x.reshape((x.shape[0], -1)) # Flatten\\n    x = nk.nn.Dense(features=256)(x)\\n    x = nk.nn.relu(x)\\n\\n    x = flax.linen.Dropout(0.5, deterministic=True)(x) # DROPOUT 2\\n\\n    x = nk.nn.Dense(features=10)(x)    # There are 10 classes in MNIST\\n    \\n    x = nk.nn.softmax(x)\\n    return x\\n\""
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# This model is from https://github.com/8bitmp3/JAX-Flax-Tutorial-Image-Classification-with-Linen with 2 dropout layers \n",
        "# I suggest that we use this model and transform it to complex which is what I'm trying to do in the cell just below\n",
        "\"\"\"\n",
        "class Model(nk.nn.Module):\n",
        "  n_classes : int = 10\n",
        "  @nk.nn.compact\n",
        "  # Provide a constructor to register a new parameter \n",
        "  # and return its initial value\n",
        "  def __call__(self, x):\n",
        "    dropout_rng = self.make_rng('dropout')\n",
        "    x = nk.nn.Conv(features=32, kernel_size=(3, 3))(x)\n",
        "    x = nk.nn.relu(x)\n",
        "    x = flax.linen.avg_pool(x, window_shape=(2, 2), strides=(2, 2)) # With max pool it diverges. Don't ask me why\n",
        "\n",
        "    \n",
        "\n",
        "    x = nk.nn.Conv(features=64, kernel_size=(3, 3))(x)\n",
        "\n",
        "    x = flax.linen.Dropout(0.5, deterministic=True)(x) #DROPOUT 1\n",
        "\n",
        "    x = nk.nn.relu(x)\n",
        "    x = flax.linen.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
        "\n",
        "    x = x.reshape((x.shape[0], -1)) # Flatten\n",
        "    x = nk.nn.Dense(features=256)(x)\n",
        "    x = nk.nn.relu(x)\n",
        "\n",
        "    x = flax.linen.Dropout(0.5, deterministic=True)(x) # DROPOUT 2\n",
        "\n",
        "    x = nk.nn.Dense(features=10)(x)    # There are 10 classes in MNIST\n",
        "    \n",
        "    x = nk.nn.softmax(x)\n",
        "    return x\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "ePoAUw5oqWa3",
      "metadata": {
        "id": "ePoAUw5oqWa3"
      },
      "outputs": [],
      "source": [
        "# Same model as above but complex\n",
        "\n",
        "class Model(nk.nn.Module):\n",
        "  n_classes : int = 10\n",
        "  @nk.nn.compact\n",
        "  # Provide a constructor to register a new parameter \n",
        "  # and return its initial value\n",
        "  def __call__(self, x):\n",
        "    #dropout_rng = self.make_rng('dropout')\n",
        "\n",
        "    x = nk.nn.Conv(features=32, kernel_size=(3, 3), dtype=complex)(x)\n",
        "\n",
        "    # bias1 = self.param('bias1', jax.nn.initializers.zeros, (28,28,32))\n",
        "    # x = modRelu(x, bias1)\n",
        "\n",
        "    x = complex_relu(x)\n",
        "\n",
        "    x = flax.linen.avg_pool(x, window_shape=(2, 2), strides=(2, 2)) \n",
        "    \n",
        "    x = nk.nn.Conv(features=64, kernel_size=(3, 3), dtype=complex)(x)\n",
        "    #x = flax.linen.Dropout(0.5, deterministic=True)(x) #DROPOUT 1\n",
        "\n",
        "    # bias2 = self.param('bias2', jax.nn.initializers.zeros, (14,14,64))\n",
        "    # x = x = modRelu(x, bias2)\n",
        "    x = complex_relu(x)\n",
        "\n",
        "    x = flax.linen.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
        "    x = x.reshape((x.shape[0], -1)) # Flatten\n",
        "    x = nk.nn.Dense(features=256, dtype=complex)(x)\n",
        "\n",
        "    # bias3 = self.param('bias3', jax.nn.initializers.zeros, 256)\n",
        "    # x = x = modRelu(x, bias3)\n",
        "    x = complex_relu(x)\n",
        "\n",
        "    #x = flax.linen.Dropout(0.5, deterministic=True)(x) # DROPOUT 2\n",
        "\n",
        "    x = nk.nn.Dense(features=10, dtype=complex)(x)    # There are 10 classes in MNIST\n",
        "\n",
        "    x = jnp.abs(x) #<= I guess this isn't required anymore?\n",
        "    # x = nk.nn.softmax(x)\n",
        "\n",
        "    # In the Jax tutorial, log_softmax is used - should we use it too?\n",
        "    # => let's try\n",
        "    x = nk.nn.log_softmax(x)\n",
        "\n",
        "    return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "e1kVjLXlnBgE",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "e1kVjLXlnBgE",
        "outputId": "bcca5487-c33a-4ced-fe7c-050f70a4ff33"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"\\nclass Model(nk.nn.Module):\\n  n_classes : int = 10\\n  @nk.nn.compact\\n  # Provide a constructor to register a new parameter \\n  # and return its initial value\\n  def __call__(self, x):\\n    dropout_rng = self.make_rng('dropout')\\n    x = nk.nn.Conv(features=10, kernel_size=(5, 5))(x)\\n    x = nk.nn.relu(x)\\n    x = flax.linen.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\\n\\n    \\n\\n    x = nk.nn.Conv(features=20, kernel_size=(5, 5))(x)\\n\\n    x = flax.linen.Dropout(0.5, deterministic=True)(x)\\n\\n    x = nk.nn.relu(x)\\n    x = flax.linen.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\\n\\n    x = x.reshape((x.shape[0], -1)) # Flatten\\n    x = nk.nn.Dense(features=320)(x)\\n\\n    x = nk.nn.relu(x)\\n\\n    #x = flax.linen.Dropout(0.5, deterministic=True)(x)\\n    x = nk.nn.Dense(features=10)(x)    # There are 10 classes in MNIST\\n\\n    x = nk.nn.softmax(x)\\n    return x\\n\""
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# New model with other parameters which is not complex but performing much better\n",
        "# works with a low learning rate\n",
        "\"\"\"\n",
        "class Model(nk.nn.Module):\n",
        "  n_classes : int = 10\n",
        "  @nk.nn.compact\n",
        "  # Provide a constructor to register a new parameter \n",
        "  # and return its initial value\n",
        "  def __call__(self, x):\n",
        "    dropout_rng = self.make_rng('dropout')\n",
        "    x = nk.nn.Conv(features=10, kernel_size=(5, 5))(x)\n",
        "    x = nk.nn.relu(x)\n",
        "    x = flax.linen.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
        "\n",
        "    \n",
        "\n",
        "    x = nk.nn.Conv(features=20, kernel_size=(5, 5))(x)\n",
        "\n",
        "    x = flax.linen.Dropout(0.5, deterministic=True)(x)\n",
        "\n",
        "    x = nk.nn.relu(x)\n",
        "    x = flax.linen.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
        "\n",
        "    x = x.reshape((x.shape[0], -1)) # Flatten\n",
        "    x = nk.nn.Dense(features=320)(x)\n",
        "\n",
        "    x = nk.nn.relu(x)\n",
        "\n",
        "    #x = flax.linen.Dropout(0.5, deterministic=True)(x)\n",
        "    x = nk.nn.Dense(features=10)(x)    # There are 10 classes in MNIST\n",
        "\n",
        "    x = nk.nn.softmax(x)\n",
        "    return x\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "add7d9bd-8028-43e0-b62f-d1c8f05b0de7",
      "metadata": {
        "id": "add7d9bd-8028-43e0-b62f-d1c8f05b0de7"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "jax.numpy.fft.fftn only supports 1D, 2D, and 3D FFTs. Got axes None with input rank 4.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/var/folders/b0/v5cl87nj5q5_f0wrtyh4g4kw0000gn/T/ipykernel_25795/1435535940.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPRNGKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dropout'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPRNGKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed_dropout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mpars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "    \u001b[0;31m[... skipping hidden 11 frame]\u001b[0m\n",
            "\u001b[0;32m/var/folders/b0/v5cl87nj5q5_f0wrtyh4g4kw0000gn/T/ipykernel_25795/1165615151.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m#dropout_rng = self.make_rng('dropout')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfftn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcomplex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages/jax/_src/numpy/fft.py\u001b[0m in \u001b[0;36mfftn\u001b[0;34m(a, s, axes, norm)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0m_wraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfftn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfftn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_fft_core\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fftn'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxla_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFftType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFFT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Documents/Code.nosync/ws21_22/ml/ml_env/lib/python3.8/site-packages/jax/_src/numpy/fft.py\u001b[0m in \u001b[0;36m_fft_core\u001b[0;34m(func_name, fft_type, a, s, axes, norm)\u001b[0m\n\u001b[1;32m     60\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;31m# XLA does not support FFTs over more than 3 dimensions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     raise ValueError(\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0;34m\"%s only supports 1D, 2D, and 3D FFTs. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \"Got axes %s with input rank %s.\" % (full_name, orig_axes, a.ndim))\n",
            "\u001b[0;31mValueError\u001b[0m: jax.numpy.fft.fftn only supports 1D, 2D, and 3D FFTs. Got axes None with input rank 4."
          ]
        }
      ],
      "source": [
        "seed = 123\n",
        "seed_dropout = 0\n",
        "\n",
        "model = Model(n_classes=10)\n",
        "\n",
        "sample_input = jnp.ones([1, 28, 28, 1])\n",
        "\n",
        "# Dropout was added (compared to Deep Learning Tut - why?)\n",
        "\n",
        "key = {'params': jax.random.PRNGKey(seed), 'dropout': jax.random.PRNGKey(seed_dropout)}\n",
        "pars = model.init(key, sample_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qFUGKZi6tX7r",
      "metadata": {
        "id": "qFUGKZi6tX7r"
      },
      "outputs": [],
      "source": [
        "a, b = model.init_with_output(key, jnp.ones([50,28,28,1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QnlCRmVhRIBk",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QnlCRmVhRIBk",
        "outputId": "0099a33c-eef6-4d7a-eb7c-6d7e7dacb9b0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DeviceArray([-23.05910344, -23.05910344, -23.05910344, -23.05910344,\n",
              "             -23.05910344, -23.05910344, -23.05910344, -23.05910344,\n",
              "             -23.05910344, -23.05910344, -23.05910344, -23.05910344,\n",
              "             -23.05910344, -23.05910344, -23.05910344, -23.05910344,\n",
              "             -23.05910344, -23.05910344, -23.05910344, -23.05910344,\n",
              "             -23.05910344, -23.05910344, -23.05910344, -23.05910344,\n",
              "             -23.05910344, -23.05910344, -23.05910344, -23.05910344,\n",
              "             -23.05910344, -23.05910344, -23.05910344, -23.05910344,\n",
              "             -23.05910344, -23.05910344, -23.05910344, -23.05910344,\n",
              "             -23.05910344, -23.05910344, -23.05910344, -23.05910344,\n",
              "             -23.05910344, -23.05910344, -23.05910344, -23.05910344,\n",
              "             -23.05910344, -23.05910344, -23.05910344, -23.05910344,\n",
              "             -23.05910344, -23.05910344], dtype=float64)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a.sum(axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b1324af-5409-4a2c-9fc3-1ae9e09e009b",
      "metadata": {
        "id": "0b1324af-5409-4a2c-9fc3-1ae9e09e009b"
      },
      "source": [
        "Let's initialize the model:\n",
        " \n",
        " - We need a seed for the RNG that generates the initial weights\n",
        " - We need a sample input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b6Se8f-XT00",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3b6Se8f-XT00",
        "outputId": "48749140-f9c4-440c-95b0-eb8232e74a86"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "FrozenDict({\n",
              "    params: {\n",
              "        Conv_0: {\n",
              "            kernel: DeviceArray([[[[-5.82772169e-02+0.29194363j,\n",
              "                            -6.28507523e-02+0.09604123j,\n",
              "                            -1.58169942e-01-0.30979609j,\n",
              "                             1.08829532e-02-0.4999597j ,\n",
              "                             2.83268561e-01+0.27674104j,\n",
              "                            -1.16125211e-01+0.26254788j,\n",
              "                             1.03524338e-01+0.34902887j,\n",
              "                            -1.18536110e-01-0.25907359j,\n",
              "                            -2.82146829e-01+0.1126028j ,\n",
              "                             2.90606700e-01-0.1992909j ,\n",
              "                            -3.46378961e-01+0.45473043j,\n",
              "                             1.70997254e-01+0.28729596j,\n",
              "                            -2.51380538e-02-0.25188267j,\n",
              "                            -3.53411562e-02+0.2186729j ,\n",
              "                            -4.17210340e-01+0.17080983j,\n",
              "                            -5.64841642e-01-0.00770295j,\n",
              "                            -1.57674066e-01+0.35771942j,\n",
              "                            -4.06999589e-01+0.09988808j,\n",
              "                             6.07992434e-02+0.11466526j,\n",
              "                            -5.21738380e-02-0.26863156j,\n",
              "                             5.89096861e-02-0.37716778j,\n",
              "                             3.38410127e-01+0.22375623j,\n",
              "                            -2.14582319e-01+0.17278462j,\n",
              "                             2.57354722e-02+0.18236199j,\n",
              "                            -2.34835469e-01-0.20868357j,\n",
              "                             5.64222673e-02+0.46594636j,\n",
              "                             1.85449687e-01+0.10748656j,\n",
              "                             1.52670390e-01-0.30321162j,\n",
              "                            -7.25327487e-03+0.14353004j,\n",
              "                             8.91699445e-02+0.05394211j,\n",
              "                             2.95930582e-01-0.07520828j,\n",
              "                             3.83531821e-01-0.42912816j]],\n",
              "            \n",
              "                          [[ 4.65455313e-01+0.16969507j,\n",
              "                             4.45192145e-02-0.09911595j,\n",
              "                             1.28832162e-01+0.36074533j,\n",
              "                            -4.60070966e-01-0.04548388j,\n",
              "                            -4.86528676e-01-0.38066332j,\n",
              "                             2.97875019e-01-0.06062324j,\n",
              "                            -4.37691109e-01-0.24360865j,\n",
              "                             2.66735112e-01-0.20001695j,\n",
              "                            -3.83404115e-01-0.13304939j,\n",
              "                            -2.49620001e-01-0.27442535j,\n",
              "                             2.91125299e-01-0.07268248j,\n",
              "                            -7.68237208e-02+0.07190413j,\n",
              "                             3.06566131e-02+0.07100754j,\n",
              "                             1.37894311e-01-0.28992018j,\n",
              "                            -1.51620311e-01-0.06265148j,\n",
              "                             4.74075401e-01+0.08399173j,\n",
              "                             1.00431222e-02-0.01724242j,\n",
              "                             3.20919016e-01-0.16168391j,\n",
              "                            -1.30881668e-01+0.41248175j,\n",
              "                             6.42165797e-02+0.23126926j,\n",
              "                            -2.70506755e-01+0.0327286j ,\n",
              "                            -6.87627263e-02+0.20045106j,\n",
              "                             4.22815020e-01-0.42458519j,\n",
              "                            -2.20527858e-01+0.44531498j,\n",
              "                             3.02013447e-02+0.00196431j,\n",
              "                            -1.66882567e-01-0.077039j  ,\n",
              "                            -2.26486890e-01-0.13343278j,\n",
              "                             4.92276663e-02+0.19865883j,\n",
              "                            -6.73487840e-01+0.07554825j,\n",
              "                            -4.70283724e-02+0.00355684j,\n",
              "                             1.52849796e-01+0.23564213j,\n",
              "                            -2.68834309e-01+0.04167445j]],\n",
              "            \n",
              "                          [[ 1.31337563e-01+0.19784022j,\n",
              "                             1.34947778e-01-0.19905514j,\n",
              "                            -1.20995806e-01+0.1689075j ,\n",
              "                            -1.02423516e-01-0.32502757j,\n",
              "                            -4.14050942e-02-0.06872771j,\n",
              "                            -5.94909332e-01-0.13727102j,\n",
              "                            -4.66014168e-01+0.20016811j,\n",
              "                             3.95181329e-01-0.31847392j,\n",
              "                            -1.86189463e-01+0.46722804j,\n",
              "                            -4.46167800e-01-0.02220119j,\n",
              "                            -2.05718545e-01+0.4047332j ,\n",
              "                            -2.99565208e-01+0.45409792j,\n",
              "                             1.11744540e-01+0.06490488j,\n",
              "                             1.01180570e-01-0.1284739j ,\n",
              "                            -2.12778891e-01-0.07397417j,\n",
              "                            -1.96000604e-01+0.2647744j ,\n",
              "                             8.63382146e-02-0.2381889j ,\n",
              "                            -5.35306342e-02-0.27868539j,\n",
              "                            -3.71553899e-01+0.11416667j,\n",
              "                            -1.10271058e-01-0.03108321j,\n",
              "                             4.83083863e-02+0.16623439j,\n",
              "                            -3.69328210e-02+0.13776907j,\n",
              "                             9.09598016e-02+0.50453343j,\n",
              "                             3.99972928e-01-0.20683521j,\n",
              "                            -3.46648053e-01+0.12255855j,\n",
              "                            -2.04005836e-01+0.1160271j ,\n",
              "                             4.22887929e-01+0.06906772j,\n",
              "                            -1.71728406e-01-0.28962197j,\n",
              "                            -2.38949539e-01+0.16995273j,\n",
              "                            -3.66941500e-01+0.17839868j,\n",
              "                             5.10887784e-01-0.03518502j,\n",
              "                             1.11747714e-01+0.00320047j]]],\n",
              "            \n",
              "            \n",
              "                         [[[ 9.17314916e-02-0.01647462j,\n",
              "                             1.02772584e-01-0.27097363j,\n",
              "                            -2.98738912e-01+0.15828588j,\n",
              "                             1.75576195e-01-0.34966807j,\n",
              "                             3.08409831e-01+0.09318589j,\n",
              "                            -3.00829550e-01+0.26578184j,\n",
              "                            -2.81444470e-01-0.12796033j,\n",
              "                            -1.47493192e-01-0.02701097j,\n",
              "                             2.09723494e-01-0.26606408j,\n",
              "                             1.19500597e-01+0.44276579j,\n",
              "                             9.01913473e-02-0.18678575j,\n",
              "                             9.48488007e-02+0.02455686j,\n",
              "                            -2.03318125e-02+0.1431407j ,\n",
              "                            -4.41519639e-01-0.05749849j,\n",
              "                            -7.06304725e-03-0.50593537j,\n",
              "                            -3.17137282e-01+0.10494129j,\n",
              "                             2.09246436e-01-0.01201394j,\n",
              "                            -1.19614203e-01-0.01628797j,\n",
              "                            -3.27703169e-01+0.14294895j,\n",
              "                            -5.00726120e-01-0.12081943j,\n",
              "                            -1.62422826e-01+0.4898503j ,\n",
              "                             2.23663256e-01+0.11144704j,\n",
              "                            -1.10497757e-01-0.27354064j,\n",
              "                            -3.81503008e-01-0.11383629j,\n",
              "                            -4.17470489e-01+0.14791358j,\n",
              "                             4.27942881e-01+0.11358435j,\n",
              "                             2.77157518e-02-0.29265553j,\n",
              "                             3.49300317e-01-0.15911216j,\n",
              "                             1.42926767e-01+0.3023749j ,\n",
              "                             1.56340259e-01-0.04725258j,\n",
              "                             1.29001330e-01+0.20402458j,\n",
              "                            -9.73109453e-02-0.4780939j ]],\n",
              "            \n",
              "                          [[-3.38621171e-02+0.00972805j,\n",
              "                            -8.88143429e-02-0.17647618j,\n",
              "                            -1.28514666e-01-0.13641725j,\n",
              "                             1.76703349e-01-0.0736672j ,\n",
              "                            -1.62683400e-01+0.32632315j,\n",
              "                             4.35843372e-01+0.31027645j,\n",
              "                            -1.02650915e-02-0.05803134j,\n",
              "                            -1.14628728e-01+0.08293257j,\n",
              "                             1.62502649e-01-0.12925166j,\n",
              "                             1.75797746e-01-0.41234123j,\n",
              "                             3.82428563e-01-0.04031118j,\n",
              "                             7.58243946e-02+0.07714728j,\n",
              "                            -1.40538987e-01+0.07384407j,\n",
              "                             2.97004205e-03+0.07569024j,\n",
              "                            -2.36873051e-01+0.01632524j,\n",
              "                            -1.23143323e-01+0.19888261j,\n",
              "                             5.64407582e-02-0.08754598j,\n",
              "                             5.76650946e-01-0.088516j  ,\n",
              "                             3.92816640e-01+0.13630773j,\n",
              "                            -2.98461993e-01-0.00614085j,\n",
              "                            -3.59981930e-01+0.09294338j,\n",
              "                            -1.00012318e-01-0.31630186j,\n",
              "                             6.15628505e-03+0.05683349j,\n",
              "                             7.76100853e-02+0.24984293j,\n",
              "                             2.44846445e-01-0.01565107j,\n",
              "                             2.56005261e-01-0.43230374j,\n",
              "                            -6.06842781e-02+0.1766803j ,\n",
              "                             1.96762619e-01-0.21434604j,\n",
              "                            -2.79340864e-01-0.05758126j,\n",
              "                            -1.24362691e-01-0.01320749j,\n",
              "                             4.05836960e-01-0.19946218j,\n",
              "                             2.77360471e-02-0.28048426j]],\n",
              "            \n",
              "                          [[ 2.12103635e-01-0.24963367j,\n",
              "                            -1.58126358e-01-0.29755403j,\n",
              "                            -1.69064596e-01+0.25190175j,\n",
              "                             2.64634906e-01-0.17310247j,\n",
              "                            -4.35630429e-02-0.1589803j ,\n",
              "                            -1.97705084e-01-0.0615922j ,\n",
              "                             8.27253199e-02-0.44197195j,\n",
              "                             5.09353440e-02-0.2070019j ,\n",
              "                             6.40800129e-02-0.0585422j ,\n",
              "                             4.75673179e-01+0.01414773j,\n",
              "                            -2.32592214e-01+0.17513044j,\n",
              "                             1.49170926e-01-0.42126045j,\n",
              "                             4.15132558e-01+0.03244554j,\n",
              "                             6.92861828e-02+0.25063419j,\n",
              "                            -7.20308362e-02+0.19017767j,\n",
              "                             6.94408531e-02-0.65856927j,\n",
              "                             1.53078994e-01-0.42065473j,\n",
              "                            -6.73523515e-02-0.10723411j,\n",
              "                             1.38913488e-01+0.31812856j,\n",
              "                            -4.20938914e-01+0.47591494j,\n",
              "                             9.42263507e-02+0.17675824j,\n",
              "                            -3.98793378e-02+0.09027056j,\n",
              "                            -4.85884175e-01-0.16628469j,\n",
              "                            -1.78986522e-01-0.05446202j,\n",
              "                            -2.59542159e-01+0.03698819j,\n",
              "                            -1.70180425e-02-0.1836004j ,\n",
              "                             3.66286976e-01-0.25609007j,\n",
              "                            -1.42908236e-01+0.2555806j ,\n",
              "                             1.46042989e-01-0.24173491j,\n",
              "                            -1.75165554e-01-0.02684708j,\n",
              "                            -2.42777661e-01+0.4293572j ,\n",
              "                             3.65657930e-01+0.16579777j]]],\n",
              "            \n",
              "            \n",
              "                         [[[-1.65713976e-01+0.26355002j,\n",
              "                            -1.69234050e-01-0.23794053j,\n",
              "                             6.08910710e-01+0.24337208j,\n",
              "                             3.45926220e-02+0.06593984j,\n",
              "                             1.81095405e-01-0.02973482j,\n",
              "                            -3.11937500e-01+0.5073884j ,\n",
              "                            -2.47721538e-02-0.15657618j,\n",
              "                            -1.05550891e-01+0.51343433j,\n",
              "                             1.87220324e-02+0.0353375j ,\n",
              "                             1.43370799e-02-0.65758382j,\n",
              "                             1.90979380e-01-0.00700097j,\n",
              "                            -2.85194745e-01+0.3869596j ,\n",
              "                             5.96754910e-03+0.15648515j,\n",
              "                             2.04046087e-01-0.11630697j,\n",
              "                            -4.28293581e-01+0.33981302j,\n",
              "                             5.17643677e-02+0.07618326j,\n",
              "                            -2.37581000e-02+0.04194581j,\n",
              "                             2.23773491e-01-0.0974521j ,\n",
              "                            -1.01277189e-01-0.35554906j,\n",
              "                             1.01092570e-01-0.57834448j,\n",
              "                            -5.51409430e-02+0.2023809j ,\n",
              "                            -4.62393338e-02+0.02420879j,\n",
              "                             2.53483992e-01-0.47274328j,\n",
              "                             1.38544325e-01-0.24194868j,\n",
              "                             1.92647824e-01-0.26216637j,\n",
              "                            -9.39734767e-02+0.53749162j,\n",
              "                            -5.58385422e-01+0.39526808j,\n",
              "                             1.50814418e-01-0.26544316j,\n",
              "                            -2.38579971e-01-0.20166652j,\n",
              "                            -1.83996134e-01-0.19465121j,\n",
              "                             2.91017749e-01+0.12858615j,\n",
              "                            -1.22204928e-01+0.50181336j]],\n",
              "            \n",
              "                          [[-2.71400732e-01+0.06216103j,\n",
              "                            -2.70149113e-01-0.27350068j,\n",
              "                            -4.44599945e-01+0.14547533j,\n",
              "                             2.10016517e-01+0.18453707j,\n",
              "                            -7.88364445e-02+0.22357918j,\n",
              "                            -3.02051389e-01-0.04990667j,\n",
              "                             5.02670651e-03-0.302188j  ,\n",
              "                            -2.30489999e-01+0.35619846j,\n",
              "                             1.65220036e-01+0.11698844j,\n",
              "                            -2.92331599e-01-0.09748223j,\n",
              "                             2.41647072e-01-0.19352682j,\n",
              "                            -1.58320852e-01+0.19273724j,\n",
              "                             1.47314223e-01+0.11828216j,\n",
              "                            -2.14854165e-01-0.24507219j,\n",
              "                            -1.92521517e-01-0.08960804j,\n",
              "                            -9.77486978e-02-0.09083921j,\n",
              "                             2.98158040e-02-0.46621098j,\n",
              "                             2.43381506e-01+0.1197826j ,\n",
              "                            -3.34197019e-01-0.38215748j,\n",
              "                             3.35430215e-02+0.00315037j,\n",
              "                             1.39155747e-01-0.02541987j,\n",
              "                            -5.08076314e-02+0.17773143j,\n",
              "                             7.46316772e-02+0.40368196j,\n",
              "                            -1.51880935e-02-0.13286858j,\n",
              "                             2.09335532e-01+0.40252639j,\n",
              "                             5.86994946e-02+0.14959457j,\n",
              "                            -2.41993342e-01-0.21860524j,\n",
              "                             4.29300233e-01+0.25884083j,\n",
              "                             7.37742360e-02+0.12938958j,\n",
              "                            -3.23456054e-01+0.13074225j,\n",
              "                            -2.12615534e-01-0.05478065j,\n",
              "                            -2.42739903e-01-0.30620546j]],\n",
              "            \n",
              "                          [[ 4.16463430e-03+0.07568077j,\n",
              "                            -5.01432454e-02-0.17625428j,\n",
              "                             8.68891538e-02+0.18680103j,\n",
              "                             3.90065019e-05-0.1120699j ,\n",
              "                             1.41673713e-01-0.32947174j,\n",
              "                            -2.33091085e-02+0.44082781j,\n",
              "                            -3.83442492e-01+0.02510178j,\n",
              "                             2.41988113e-01-0.13093929j,\n",
              "                             3.78881584e-02-0.2081493j ,\n",
              "                            -2.08082260e-01-0.13561444j,\n",
              "                             2.33757034e-01+0.26618438j,\n",
              "                             1.42874155e-01-0.12693474j,\n",
              "                             1.66842357e-01+0.24498805j,\n",
              "                            -6.66176726e-02-0.19386552j,\n",
              "                            -2.25421945e-01+0.12950458j,\n",
              "                             2.93660612e-01-0.10434983j,\n",
              "                             1.85572084e-01-0.06116186j,\n",
              "                            -1.96672198e-01+0.17010717j,\n",
              "                             7.56858065e-02+0.09749412j,\n",
              "                             1.04612882e-01+0.19861781j,\n",
              "                            -3.02512646e-01-0.07832748j,\n",
              "                            -2.51633234e-02+0.08985143j,\n",
              "                             1.21014414e-01+0.22096399j,\n",
              "                            -8.53234613e-03-0.23499288j,\n",
              "                             2.25237004e-01+0.19800504j,\n",
              "                             2.05806786e-01+0.18464689j,\n",
              "                             3.20784958e-01-0.21105843j,\n",
              "                             4.81668822e-01-0.21893194j,\n",
              "                             2.49491202e-01-0.58720921j,\n",
              "                             8.74760954e-02-0.55805649j,\n",
              "                             1.41046021e-01+0.09014585j,\n",
              "                            -3.17775884e-01-0.08730256j]]]], dtype=complex128),\n",
              "            bias: DeviceArray([0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
              "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
              "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
              "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
              "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j], dtype=complex128),\n",
              "        },\n",
              "        Conv_1: {\n",
              "            kernel: DeviceArray([[[[ 0.03482234+0.03095743j, -0.03493748-0.02076547j,\n",
              "                            -0.04375343-0.0239546j , ...,  0.02491834+0.01291011j,\n",
              "                            -0.0175787 +0.03157479j,  0.07051917-0.05662623j],\n",
              "                           [ 0.00472411+0.03592918j, -0.00213038+0.07487791j,\n",
              "                             0.04308604+0.00872155j, ...,  0.02167122-0.00605535j,\n",
              "                            -0.03683185+0.1008195j , -0.00219845-0.06815094j],\n",
              "                           [ 0.02730436+0.04646041j, -0.06775723+0.03166591j,\n",
              "                             0.0743866 -0.02367132j, ..., -0.07077232+0.02137569j,\n",
              "                             0.04555017+0.00521124j, -0.01108357+0.01460357j],\n",
              "                           ...,\n",
              "                           [ 0.00923507+0.01248469j, -0.04096933+0.06736743j,\n",
              "                            -0.01098566-0.03371005j, ...,  0.00806781+0.04394274j,\n",
              "                             0.00497748-0.01746109j,  0.03157706-0.02370416j],\n",
              "                           [ 0.04552322+0.01021606j,  0.02824224-0.02919954j,\n",
              "                             0.0126067 +0.03331684j, ...,  0.04982284-0.02595386j,\n",
              "                             0.03576543-0.028629j  ,  0.01002036-0.01151737j],\n",
              "                           [-0.01795196+0.00980297j,  0.01680092+0.09289152j,\n",
              "                            -0.01398638+0.02430201j, ..., -0.00116731+0.03409231j,\n",
              "                            -0.02503092-0.02289507j, -0.07768832-0.00140969j]],\n",
              "            \n",
              "                          [[-0.03096076-0.02881452j,  0.03627845-0.01467034j,\n",
              "                             0.00599171-0.04531322j, ...,  0.00599117-0.06008617j,\n",
              "                             0.04869657-0.04575525j,  0.04349168+0.00101699j],\n",
              "                           [ 0.01870701-0.01487339j,  0.00485689+0.05420156j,\n",
              "                            -0.03220804+0.04769806j, ...,  0.04629443+0.00580715j,\n",
              "                             0.00637359+0.02214924j, -0.03487761+0.03015829j],\n",
              "                           [-0.02151351-0.06106704j, -0.02835454+0.07892759j,\n",
              "                            -0.00222006+0.00642612j, ...,  0.02263997-0.09400637j,\n",
              "                             0.00506652+0.01334276j, -0.02594505+0.02967361j],\n",
              "                           ...,\n",
              "                           [ 0.00711393-0.00536838j,  0.02448177+0.00358612j,\n",
              "                            -0.03083912-0.09801801j, ...,  0.02177475-0.00191255j,\n",
              "                             0.0419647 +0.01189472j,  0.00596233+0.01098253j],\n",
              "                           [-0.05743581-0.04339249j, -0.01542497+0.01416307j,\n",
              "                            -0.03069013+0.01232839j, ...,  0.00174241+0.04468443j,\n",
              "                             0.03875687+0.03249929j,  0.00881621-0.0734093j ],\n",
              "                           [ 0.00591108-0.01241227j, -0.0112367 -0.02459668j,\n",
              "                            -0.01826496-0.06012163j, ...,  0.0004941 +0.01424768j,\n",
              "                            -0.00232885+0.01250343j, -0.01772189-0.01049671j]],\n",
              "            \n",
              "                          [[ 0.04086556-0.01025014j, -0.00130935-0.00724153j,\n",
              "                            -0.02486065+0.01683304j, ...,  0.05992134-0.04015754j,\n",
              "                            -0.02696367-0.04635438j, -0.0397663 -0.07601598j],\n",
              "                           [-0.03840074+0.03126338j,  0.01554346+0.0719401j ,\n",
              "                            -0.04656709-0.00064538j, ..., -0.04164648-0.01645123j,\n",
              "                             0.03737531-0.08720096j, -0.08797581-0.02663946j],\n",
              "                           [ 0.06617318+0.02827778j, -0.05194732-0.02061324j,\n",
              "                            -0.00609713-0.0346503j , ..., -0.01115417-0.00566343j,\n",
              "                             0.02347407-0.01499719j, -0.00047244-0.062564j  ],\n",
              "                           ...,\n",
              "                           [ 0.016186  -0.07071969j,  0.06041606+0.0013908j ,\n",
              "                            -0.00204494-0.05479937j, ..., -0.01206347-0.00953804j,\n",
              "                             0.01387939+0.01142519j,  0.06827804-0.00052374j],\n",
              "                           [-0.03107786-0.00929933j,  0.00197645-0.03761125j,\n",
              "                            -0.06194622+0.01517664j, ..., -0.00675314+0.01405836j,\n",
              "                             0.03603373+0.0897334j ,  0.03137581-0.0233704j ],\n",
              "                           [-0.011542  -0.01339844j,  0.06533881+0.01900501j,\n",
              "                             0.0469201 -0.00905274j, ...,  0.02086875+0.04661913j,\n",
              "                             0.0047786 -0.05948972j,  0.05550821+0.00266234j]]],\n",
              "            \n",
              "            \n",
              "                         [[[-0.00739908-0.04047845j, -0.02520156-0.03820732j,\n",
              "                             0.00987231-0.02073619j, ..., -0.02622228-0.08479555j,\n",
              "                            -0.04966649+0.02516316j,  0.01229815-0.01553866j],\n",
              "                           [-0.01758949+0.02158709j, -0.01277409-0.10311904j,\n",
              "                            -0.02621247+0.05389592j, ..., -0.01685756-0.0646777j ,\n",
              "                             0.02348607+0.06057256j,  0.05774566+0.00925315j],\n",
              "                           [-0.04029479+0.07930255j,  0.07672138-0.03535072j,\n",
              "                            -0.00443778-0.03642204j, ..., -0.04324635-0.03853513j,\n",
              "                             0.00614776-0.04099689j,  0.05948791-0.02770783j],\n",
              "                           ...,\n",
              "                           [-0.03589699-0.00612841j, -0.02478058-0.00411575j,\n",
              "                            -0.00459379-0.03278982j, ..., -0.04113766-0.05248188j,\n",
              "                             0.03270591-0.0756566j ,  0.01303114-0.01168042j],\n",
              "                           [-0.06219921+0.01415236j, -0.02765798+0.07774929j,\n",
              "                            -0.02425202-0.02313663j, ..., -0.05035084-0.0084395j ,\n",
              "                            -0.02181763-0.04293394j,  0.02681843-0.04129121j],\n",
              "                           [-0.00517714-0.02661643j, -0.03150057-0.03964495j,\n",
              "                             0.00137364+0.00567223j, ...,  0.01550008+0.00766186j,\n",
              "                             0.02128117-0.0345283j ,  0.03118763-0.01669058j]],\n",
              "            \n",
              "                          [[-0.00946499-0.08660514j, -0.00741554+0.00021613j,\n",
              "                             0.0289353 -0.01795608j, ...,  0.09245613+0.04843209j,\n",
              "                             0.02914987+0.01718153j, -0.03571832+0.01655532j],\n",
              "                           [-0.01314144+0.03661299j, -0.0042907 +0.00815333j,\n",
              "                             0.0774503 -0.05653615j, ...,  0.04421613-0.10519024j,\n",
              "                            -0.06124237-0.00904844j,  0.01078101+0.0068779j ],\n",
              "                           [ 0.0048596 -0.01800465j,  0.0156912 +0.00577473j,\n",
              "                            -0.00292428+0.04225604j, ..., -0.08956331-0.04478056j,\n",
              "                            -0.09263206+0.03221093j,  0.01671437+0.02368125j],\n",
              "                           ...,\n",
              "                           [ 0.0083968 -0.02651003j, -0.02036333+0.02552295j,\n",
              "                             0.02047267+0.02369934j, ..., -0.05060646-0.00129636j,\n",
              "                            -0.00870138-0.0256406j , -0.03413999-0.01804421j],\n",
              "                           [-0.06533098-0.00271677j,  0.02022287-0.0042271j ,\n",
              "                             0.02356731-0.04821701j, ...,  0.04831822-0.01367759j,\n",
              "                             0.04894182+0.02228088j, -0.03587157+0.01199438j],\n",
              "                           [-0.01778438-0.00802067j,  0.04459663-0.00582603j,\n",
              "                            -0.01332948+0.05345174j, ...,  0.03207416+0.03762383j,\n",
              "                            -0.1089303 -0.04166652j, -0.02089066-0.05098331j]],\n",
              "            \n",
              "                          [[ 0.05843508+0.04764175j,  0.03228656+0.04867017j,\n",
              "                             0.01981429-0.04345887j, ...,  0.02172439-0.02817931j,\n",
              "                            -0.03159406+0.03450636j,  0.08246113-0.02706564j],\n",
              "                           [ 0.01157033-0.08383736j, -0.06092072+0.03643163j,\n",
              "                             0.00610527-0.05490119j, ..., -0.01768595-0.00282318j,\n",
              "                             0.02162451-0.09368527j,  0.00882788-0.03175146j],\n",
              "                           [-0.05830017-0.03318848j, -0.03882695+0.03594168j,\n",
              "                             0.02710397+0.0549146j , ...,  0.02952221-0.0237322j ,\n",
              "                             0.01961783-0.00070744j, -0.01412759-0.04146414j],\n",
              "                           ...,\n",
              "                           [ 0.01186478+0.09163568j,  0.02294204+0.03811735j,\n",
              "                             0.04267477+0.06742877j, ...,  0.04935715-0.03245886j,\n",
              "                             0.07924388+0.01998911j,  0.01976891-0.02808864j],\n",
              "                           [-0.02669167+0.04828747j, -0.02589402+0.07146578j,\n",
              "                            -0.07527087+0.03047658j, ...,  0.00496054+0.03608778j,\n",
              "                             0.05745455-0.04701955j,  0.03763792-0.01221029j],\n",
              "                           [ 0.02064725+0.05138867j, -0.02938535-0.04277956j,\n",
              "                            -0.04810987-0.00547527j, ..., -0.00701361-0.00058744j,\n",
              "                             0.01693402-0.0743197j , -0.07966983+0.03092814j]]],\n",
              "            \n",
              "            \n",
              "                         [[[ 0.04113882-0.03784276j, -0.01148897-0.0707882j ,\n",
              "                             0.01196436-0.00753912j, ...,  0.03112344-0.05441579j,\n",
              "                            -0.07291996-0.02319837j,  0.02437895+0.00765043j],\n",
              "                           [ 0.01126438-0.0095442j ,  0.00169729-0.04505463j,\n",
              "                             0.07805749+0.00371271j, ...,  0.00101987-0.03423512j,\n",
              "                            -0.05846393-0.02676198j,  0.02831571-0.05209141j],\n",
              "                           [-0.054502  -0.0231922j ,  0.01743814+0.05369597j,\n",
              "                             0.01255402+0.07779525j, ...,  0.04790648+0.0033377j ,\n",
              "                             0.03458898+0.05421688j,  0.0362873 +0.01275647j],\n",
              "                           ...,\n",
              "                           [-0.03565944-0.02161789j,  0.00853516-0.05374192j,\n",
              "                            -0.03886983+0.00722586j, ...,  0.03369293+0.01671713j,\n",
              "                            -0.0490187 -0.01446194j,  0.01034379+0.01442978j],\n",
              "                           [ 0.02522832-0.10477759j, -0.05630907+0.07105921j,\n",
              "                             0.04496324-0.01486476j, ..., -0.03454873-0.08375008j,\n",
              "                            -0.02838003+0.03890059j, -0.04037192+0.00747424j],\n",
              "                           [-0.05620413-0.03434191j, -0.04748479-0.04773013j,\n",
              "                            -0.017828  +0.04835415j, ...,  0.01361079+0.03890276j,\n",
              "                             0.03734003-0.02042901j,  0.00948691-0.02124074j]],\n",
              "            \n",
              "                          [[-0.04030041-0.03677586j, -0.02819786-0.05125115j,\n",
              "                            -0.06318927-0.04405806j, ...,  0.10100383+0.04800159j,\n",
              "                             0.07091224+0.01199588j,  0.00242267+0.03284426j],\n",
              "                           [-0.066937  -0.0228253j , -0.06959972-0.08197798j,\n",
              "                            -0.04253063-0.03614676j, ...,  0.10058032-0.03387716j,\n",
              "                             0.01937906+0.00996431j,  0.02878125+0.04783472j],\n",
              "                           [-0.00296126-0.03153914j, -0.07961685-0.02319021j,\n",
              "                            -0.02553554+0.00676499j, ...,  0.0395816 -0.04295862j,\n",
              "                            -0.01557588+0.01507385j, -0.02654259-0.0477337j ],\n",
              "                           ...,\n",
              "                           [-0.0249464 -0.03142358j,  0.04703369-0.04344802j,\n",
              "                            -0.05044467-0.00527502j, ..., -0.0286504 +0.04424941j,\n",
              "                            -0.02464607-0.02085706j, -0.09259038+0.04602525j],\n",
              "                           [ 0.03526206-0.04862034j, -0.09416284+0.04150506j,\n",
              "                            -0.01463136-0.00114503j, ..., -0.01664403+0.04308569j,\n",
              "                             0.0496546 +0.04739707j,  0.01350764-0.07252463j],\n",
              "                           [-0.08748839+0.02544408j,  0.00582809-0.00328244j,\n",
              "                             0.06516945-0.04414672j, ...,  0.01654481+0.02002647j,\n",
              "                            -0.05192694-0.02710955j,  0.00883981-0.03566636j]],\n",
              "            \n",
              "                          [[ 0.00048873-0.0933818j ,  0.03794024-0.00588173j,\n",
              "                             0.04474441-0.03003041j, ..., -0.0022995 -0.04623683j,\n",
              "                             0.00858391-0.04962933j,  0.00317031-0.06188686j],\n",
              "                           [ 0.02493256+0.0345505j , -0.00470002-0.00216242j,\n",
              "                            -0.00129293-0.07741508j, ...,  0.01333852+0.06177928j,\n",
              "                             0.04119208+0.0809644j , -0.03793275+0.01421186j],\n",
              "                           [ 0.06340757+0.0062491j ,  0.0639681 -0.05725472j,\n",
              "                            -0.02770126+0.04822938j, ...,  0.00051732+0.05953637j,\n",
              "                             0.02068629-0.0514216j ,  0.03805289-0.02938008j],\n",
              "                           ...,\n",
              "                           [ 0.01266815-0.02810366j, -0.01640012-0.07698874j,\n",
              "                            -0.05513754-0.00315611j, ...,  0.00275977+0.04407627j,\n",
              "                             0.06014267-0.00657596j, -0.03849079-0.02687252j],\n",
              "                           [ 0.0222428 +0.01561745j,  0.04239855-0.02679922j,\n",
              "                            -0.02382878-0.01774163j, ...,  0.00654835-0.00703072j,\n",
              "                             0.08594643-0.00457872j,  0.00991222-0.07496342j],\n",
              "                           [ 0.03762558+0.09069966j,  0.01104344+0.02443344j,\n",
              "                             0.02345184+0.0079308j , ..., -0.03765092+0.09974944j,\n",
              "                             0.04195664+0.00808922j, -0.00711321-0.01335978j]]]],            dtype=complex128),\n",
              "            bias: DeviceArray([0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
              "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
              "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
              "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
              "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
              "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
              "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
              "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
              "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
              "                         0.+0.j], dtype=complex128),\n",
              "        },\n",
              "        Dense_0: {\n",
              "            kernel: DeviceArray([[-0.00043805+0.0216163j , -0.00330651-0.0051889j ,\n",
              "                          -0.00094935+0.00525378j, ...,  0.00634915-0.0134044j ,\n",
              "                          -0.0198508 -0.01853866j, -0.00043443+0.00892607j],\n",
              "                         [-0.00419066-0.00551281j, -0.01392447+0.01769329j,\n",
              "                           0.01735105+0.01430123j, ...,  0.01695513+0.01357991j,\n",
              "                          -0.0093178 -0.00275035j, -0.01058093-0.00699949j],\n",
              "                         [-0.0090597 -0.00483106j,  0.01755417+0.01171472j,\n",
              "                           0.01126804+0.00257518j, ...,  0.00920114-0.00385838j,\n",
              "                           0.0021842 -0.00900351j,  0.00871633+0.0215766j ],\n",
              "                         ...,\n",
              "                         [ 0.00225832-0.01247211j,  0.00049717-0.01971836j,\n",
              "                          -0.01762597-0.01134032j, ...,  0.00720588-0.02386846j,\n",
              "                          -0.00297984+0.01575289j,  0.00250164-0.01518775j],\n",
              "                         [ 0.01647148-0.00030906j, -0.00611536-0.00263544j,\n",
              "                          -0.03235728+0.00461409j, ...,  0.00513343-0.00736959j,\n",
              "                          -0.01690031-0.01394483j, -0.00250813-0.02787838j],\n",
              "                         [-0.00207475+0.01566063j,  0.00049216+0.00182149j,\n",
              "                           0.00800676-0.00856403j, ...,  0.00403975-0.021287j  ,\n",
              "                          -0.01319485-0.02276621j,  0.00180646+0.00672091j]],            dtype=complex128),\n",
              "            bias: DeviceArray([0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
              "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
              "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
              "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
              "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
              "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
              "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
              "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
              "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
              "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
              "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
              "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
              "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
              "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
              "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
              "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
              "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
              "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
              "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
              "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
              "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
              "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
              "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
              "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
              "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
              "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
              "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
              "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
              "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
              "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
              "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
              "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
              "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
              "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
              "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
              "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
              "                         0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j], dtype=complex128),\n",
              "        },\n",
              "        Dense_1: {\n",
              "            kernel: DeviceArray([[ 0.02571171+0.00667496j,  0.01818865+0.03476768j,\n",
              "                          -0.02975401-0.01123561j, ...,  0.01867569-0.00573767j,\n",
              "                          -0.04099714-0.03560352j,  0.00483609+0.02600795j],\n",
              "                         [ 0.03800599-0.06318171j, -0.03253668+0.06502207j,\n",
              "                           0.02504367+0.01371072j, ...,  0.0076168 -0.00794348j,\n",
              "                          -0.05459801-0.02422021j, -0.03069208-0.07211422j],\n",
              "                         [-0.0138114 -0.01123484j, -0.00514056+0.03335077j,\n",
              "                          -0.03644072+0.04274664j, ..., -0.05531259-0.02518446j,\n",
              "                           0.00789196-0.02903889j,  0.03195075-0.01573669j],\n",
              "                         ...,\n",
              "                         [ 0.00119587-0.05519684j,  0.01959933-0.00424355j,\n",
              "                          -0.08662269+0.01614252j, ..., -0.07184621+0.07310146j,\n",
              "                           0.02064405-0.06809902j,  0.04506467-0.01749488j],\n",
              "                         [ 0.01379107+0.00911554j, -0.00883593+0.06330193j,\n",
              "                          -0.00887568-0.05684631j, ...,  0.07547394+0.05109712j,\n",
              "                           0.09561358+0.01229632j,  0.00898184-0.05866284j],\n",
              "                         [-0.06151762-0.02327297j,  0.02239452-0.01561381j,\n",
              "                          -0.03008847+0.01177773j, ...,  0.00628201+0.01089115j,\n",
              "                          -0.00349766+0.03550121j, -0.00781439+0.04114626j]],            dtype=complex128),\n",
              "            bias: DeviceArray([0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
              "                         0.+0.j, 0.+0.j, 0.+0.j], dtype=complex128),\n",
              "        },\n",
              "    },\n",
              "})"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pars"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7604bf44-3b6e-4550-93bf-af5253a50364",
      "metadata": {
        "id": "7604bf44-3b6e-4550-93bf-af5253a50364"
      },
      "source": [
        "we can inspect the parameters `pars`:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11ebdbb9-8e06-4620-89f8-572f752ff73e",
      "metadata": {
        "id": "11ebdbb9-8e06-4620-89f8-572f752ff73e"
      },
      "source": [
        "## 3 - Writing the loss function\n",
        "\n",
        "We now want to take as a loss function the distance between the _predicted_ probability given by the model $q_W^{(i)}(x)$ and the actualy probabilith $p^{(i)}(x)$.\n",
        "\n",
        "The actual probability is a delta function: it is zero for every label except for the correct one, for which it is 1.\n",
        "\n",
        "To perform this, we can use one-hot encoding, which takes an integer value in $i\\in[0..K]$ and returns a vector in $R^K$ where only the i-th component is 1 and the other are zero: $v_j = \\delta_{i,j}$.\n",
        "\n",
        "See the examples below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d168c699-dbc5-4f84-9f1f-40511e35050f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d168c699-dbc5-4f84-9f1f-40511e35050f",
        "outputId": "bcbb1f8e-baaf-4a45-87b3-8d808f670541"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 becomes: [1. 0. 0. 0. 0.]\n",
            "1 becomes: [0. 1. 0. 0. 0.]\n",
            "2 becomes: [0. 0. 1. 0. 0.]\n",
            "3 becomes: [0. 0. 0. 1. 0.]\n",
            "4 becomes: [0. 0. 0. 0. 1.]\n"
          ]
        }
      ],
      "source": [
        "for i in range(5):\n",
        "    print(f\"{i} becomes: {jax.nn.one_hot(i, 5)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c72691d-9a4e-4826-a042-67b0aaa3238e",
      "metadata": {
        "id": "1c72691d-9a4e-4826-a042-67b0aaa3238e"
      },
      "source": [
        "For the loss function, i'll draw from my vast knowledge of loss functions (aka: [here](https://optax.readthedocs.io/en/latest/api.html)) and choose `optax.softmax_cross_entropy`.\n",
        "\n",
        "However, for the sake of completeness, i'll write it down here by hand.\n",
        "\n",
        "`?optax.softmax_cross_entropy`\n",
        "> Computes the softmax cross entropy between sets of logits and labels.\n",
        ">\n",
        ">Measures the probability error in discrete classification tasks in which\n",
        ">the classes are mutually exclusive (each entry is in exactly one class).\n",
        ">For example, each CIFAR-10 image is labeled with one and only one label:\n",
        ">an image can be a dog or a truck, but not both.\n",
        ">\n",
        ">References:\n",
        "> [Goodfellow et al, 2016](http://www.deeplearningbook.org/contents/prob.html)\n",
        ">\n",
        ">Args:\n",
        ">\n",
        ">  logits: unnormalized log probabilities.\n",
        ">\n",
        ">  labels: a valid probability distribution (non-negative, sum to 1), e.g a\n",
        ">    one hot encoding of which class is the correct one for each input.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2b7a0b6-6157-4bf5-a6a0-39888bebe46b",
      "metadata": {
        "id": "a2b7a0b6-6157-4bf5-a6a0-39888bebe46b"
      },
      "source": [
        "The cross entropy between an approximate distribution $P_W(x)$ and a target distribution $Q(x)$ is defined as \n",
        "\n",
        "$$\n",
        "\\mathcal{L}(W) = - \\langle log P_W(x) \\rangle_{x \\approx Q(x)} = - \\sum_{x \\approx Q(x)} log P_W(x)\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "***NOTE***: why is cross-entropy such a good loss function (much better than the sum of squared residuals)?\n",
        "=> because the slope (tangent line) for cross entropy for a bad prediction will be relatively large, compared to the derivative for that same bad prediction with squared residuals. This helps us when performing gradient descent!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4112499-6b6f-445e-bd18-22fd5b0b2a78",
      "metadata": {
        "id": "e4112499-6b6f-445e-bd18-22fd5b0b2a78"
      },
      "outputs": [],
      "source": [
        "# The loss function that we will use\n",
        "def cross_entropy(*, logits, labels):\n",
        "    one_hot_labels = jax.nn.one_hot(labels, num_classes=10)\n",
        "    return -jnp.mean(jnp.sum(one_hot_labels * logits, axis=-1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Hx-ZQzpLZMj4",
      "metadata": {
        "id": "Hx-ZQzpLZMj4"
      },
      "outputs": [],
      "source": [
        "dropout_rng, init_dropout = jax.random.split(jax.random.PRNGKey(1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e90668ed-0090-446a-81d3-4f6e1763b2e2",
      "metadata": {
        "id": "e90668ed-0090-446a-81d3-4f6e1763b2e2"
      },
      "outputs": [],
      "source": [
        "def loss_fn(params, dropout_rng, images, labels):\n",
        "    \"\"\"\n",
        "    Loss function minimised during training of the model.\n",
        "    \"\"\"\n",
        "    # compute the output of the model, which gives the \n",
        "    # log-probability distribution over the possible classes (0...9)\n",
        "    logits = model.apply(params, images, rngs={'dropout' : dropout_rng})\n",
        "    # feed it to the cross_entropy\n",
        "    return cross_entropy(logits=logits, labels=labels)\n",
        "\n",
        "def compute_metrics(*, logits, labels):\n",
        "    \"\"\"\n",
        "    Compute metrics of the model during training.\n",
        "    \n",
        "    Returns the loss and the accuracy.\n",
        "    \"\"\"\n",
        "    loss = cross_entropy(logits=logits, labels=labels)\n",
        "    accuracy = jnp.mean(jnp.argmax(logits, -1) == labels)\n",
        "    metrics = {\n",
        "      'loss': loss,\n",
        "      'accuracy': accuracy,\n",
        "    }\n",
        "    return metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff0ff54a-3d6a-42e7-bdf3-23a9b0d899fd",
      "metadata": {
        "id": "ff0ff54a-3d6a-42e7-bdf3-23a9b0d899fd"
      },
      "source": [
        "## 4 - Create the setup and training loop\n",
        "\n",
        "We need to define some functions to create the initial state and we need to define a function to execute one training step, and the whole training loop.\n",
        "\n",
        "For the optimiser, we use optimisers defined in "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50082ccb-9022-496a-8898-f2b645116347",
      "metadata": {
        "id": "50082ccb-9022-496a-8898-f2b645116347"
      },
      "outputs": [],
      "source": [
        "import optax\n",
        "from flax.training import train_state  # Useful dataclass to keep train state\n",
        "\n",
        "def create_train_state(rng, optimiser, dropout_rng):\n",
        "    \"\"\"Creates initial `TrainState`, holding the current parameters, state of the\n",
        "    optimiser and other metadata.\n",
        "    \"\"\"\n",
        "    # Construct the model parameters\n",
        "    params = model.init({'params' : rng, 'dropout' : dropout_rng}, jnp.ones([1, 28, 28, 1]))\n",
        "        \n",
        "    # Package all those informations in the model state\n",
        "    return train_state.TrainState.create(\n",
        "        apply_fn=model.apply, params=params, tx=optimiser)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d0ec7de-f082-4276-96e6-86c59712ba69",
      "metadata": {
        "id": "4d0ec7de-f082-4276-96e6-86c59712ba69"
      },
      "outputs": [],
      "source": [
        "@jax.jit\n",
        "def eval_metrics(params, batch, dropout_rng):\n",
        "    \"\"\"\n",
        "    This function evaluates the metrics without training the model.\n",
        "    \n",
        "    Used to check the performance of the network on training and test datasets.\n",
        "    \"\"\"\n",
        "    logits = model.apply(params, batch['image'], rngs={'dropout' : dropout_rng})\n",
        "    return compute_metrics(logits=logits, labels=batch['label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f6b6254-da8a-4bd5-ad56-15b13a3c2bd2",
      "metadata": {
        "id": "5f6b6254-da8a-4bd5-ad56-15b13a3c2bd2"
      },
      "outputs": [],
      "source": [
        "# Partial is handy as it can be used to 'fix' some arguments to a function.\n",
        "# so partial(f, x)(y) == f(x,y)\n",
        "from functools import partial\n",
        "\n",
        "@jax.jit\n",
        "def train_step(state, batch, dropout_rng):\n",
        "    \"\"\"\n",
        "    Train for a single step.\n",
        "    \n",
        "    The input images `batch` should not be too large, otherwise we will run\n",
        "    out of memory. Therefore the input should be 'batched', meaning should be\n",
        "    separated into small blocks of ~hundreds (instead of tens of thousands)\n",
        "    iamges.\n",
        "    \"\"\"\n",
        "    # Fix some arguments to the loss function (so that the only 'free' parameter is\n",
        "    # the parameters of the network.\n",
        "    _loss_fn = partial(loss_fn, dropout_rng = dropout_rng, images=batch['image'], labels=batch['label'])\n",
        "    # construct the function returning the loss value and gradient.\n",
        "    val_grad_fn = jax.value_and_grad(_loss_fn)\n",
        "    # compute loss and gradient\n",
        "    loss, grads = val_grad_fn(state.params)\n",
        "\n",
        "    # NEW: MANUALLY CONJUGATE THE GRADIENTS!!!! THANKS DIAN <3\n",
        "    grads = jax.tree_map(lambda x: x.conj(), grads) # <- Add this!\n",
        "\n",
        "    # update the state parameters with the new gradients\n",
        "    # objects are immutable so the output of this function is a different\n",
        "    # object than the starting one.\n",
        "    state = state.apply_gradients(grads=grads)\n",
        "    \n",
        "    # Evaluate the network again to get the log-probability distribution\n",
        "    # over the batch images\n",
        "    metrics = eval_metrics(state.params, batch, dropout_rng)\n",
        "    \n",
        "    return state, metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2f17cf0-198d-4d57-88d9-de60e6e76492",
      "metadata": {
        "id": "e2f17cf0-198d-4d57-88d9-de60e6e76492"
      },
      "outputs": [],
      "source": [
        "def train_epoch(state, train_ds, batch_size, epoch, rng, dropout_rng, *, max_steps=None):\n",
        "    \"\"\"Train for a single `epoch`.\n",
        "    \n",
        "    And epoch is composed of several steps, where every step is taken by updating\n",
        "    the network parameters with a small mini-batch.\n",
        "    \"\"\"\n",
        "    \n",
        "    # total number of training images\n",
        "    train_ds_size = len(train_ds['image'])\n",
        "    \n",
        "    # Compute how many steps are present in this epoch.\n",
        "    # In one epoch we want to go through the whole dataset.\n",
        "    steps_per_epoch = train_ds_size // batch_size\n",
        "\n",
        "    # Truncate the number of steps (used to speed up training)\n",
        "    # Sometimes we might want not to go through the whole dataset\n",
        "    # in an epoch.\n",
        "    if max_steps is not None:\n",
        "        steps_per_epoch = min(steps_per_epoch, max_steps)\n",
        "\n",
        "    # generate a random permutation of the indices to shuffle the training\n",
        "    # dataset, and reshape it to a set of batches.\n",
        "    perms = jax.random.permutation(rng, train_ds_size)\n",
        "    perms = perms[:steps_per_epoch * batch_size]\n",
        "    perms = perms.reshape((steps_per_epoch, batch_size))\n",
        "    \n",
        "    # execute the training step for every mini-batch\n",
        "    batch_metrics = []\n",
        "    for perm in perms:\n",
        "        batch = {k: v[perm, ...] for k, v in train_ds.items()}\n",
        "        state, metrics = train_step(state, batch, dropout_rng)\n",
        "        batch_metrics.append(metrics)\n",
        "\n",
        "    # compute mean of metrics across each batch in epoch.\n",
        "    batch_metrics_np = jax.device_get(batch_metrics)\n",
        "    epoch_metrics_np = {\n",
        "        k: np.mean([metrics[k] for metrics in batch_metrics_np])\n",
        "            for k in batch_metrics_np[0]}\n",
        "\n",
        "    return state, epoch_metrics_np\n",
        "\n",
        "\n",
        "def evaluate_model(params, test_ds, dropout_rng):\n",
        "    \"\"\"\n",
        "    evaluate the performance of the model on the test dataset\n",
        "    \"\"\"\n",
        "    metrics = eval_metrics(params, test_ds, dropout_rng)\n",
        "    metrics = jax.device_get(metrics)\n",
        "    summary = jax.tree_map(lambda x: x.item(), metrics)\n",
        "    return summary['loss'], summary['accuracy']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed1db647-2349-46d8-8f6f-8bebedf73872",
      "metadata": {
        "id": "ed1db647-2349-46d8-8f6f-8bebedf73872"
      },
      "source": [
        "# 5 - Running the optimisation\n",
        "\n",
        "We will now finally run the optimisation.  Below we will define all the required HyperParameters.\n",
        "\n",
        "For the optimiser, we pick one from the [optax](https://optax.readthedocs.io) package, which is very comprehensive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1123ddd-9083-4122-b47d-07513797aad3",
      "metadata": {
        "id": "d1123ddd-9083-4122-b47d-07513797aad3"
      },
      "outputs": [],
      "source": [
        "# Definition of optimiser HyperParameters\n",
        "\n",
        "learning_rate = 0.01\n",
        "\"\"\"\n",
        "Standard SGD step size\n",
        "\"\"\"\n",
        "momentum = 0.9\n",
        "\"\"\"\n",
        "Amount of memntum. The maximum effective learning rate will be\n",
        "$ learning_rate * momentum/(1-momentum)$\n",
        "\"\"\"\n",
        "\n",
        "# Construct the optimiser\n",
        "# we use optimisers from the optax package which is a very comprehensive\n",
        "# optimiser library\n",
        "optimiser = optax.sgd(learning_rate, momentum)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afae251b-a760-4156-ae09-51e4476d769d",
      "metadata": {
        "id": "afae251b-a760-4156-ae09-51e4476d769d"
      },
      "outputs": [],
      "source": [
        "num_epochs = 10\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "\n",
        "batch_size = 32\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "\n",
        "max_steps = 200\n",
        "\"\"\"\n",
        "Cutoff to the number of steps (minibatches) in an epoch\n",
        "\"\"\";"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e7263bc-b1f0-4a71-8b2a-ff19daf8257b",
      "metadata": {
        "id": "6e7263bc-b1f0-4a71-8b2a-ff19daf8257b"
      },
      "outputs": [],
      "source": [
        "# Split the rng to get two keys, one to 'shuffle' the dataset at every iteration,\n",
        "# and one to initialise the network\n",
        "rng, init_rng = jax.random.split(jax.random.PRNGKey(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a077215-b821-45cf-8747-cd7154f4351a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396,
          "referenced_widgets": [
            "ca9e12c942d44da198e547847a9858e8",
            "7d8e72ccff7a4e879b6337b7c5d7c661",
            "697375ac698e4bc8a872c12933b4a522",
            "dde09fc3f18f4b1c91fb42f7111e0500",
            "acf2fc1089844f0c9e7790b157c892d6",
            "9b160d0b614c4b0eb031b800bfd12aa4",
            "5bd5b0f8ff3441c1be0e851acee6ecde",
            "8f1a2792ffd04a798b7bd3ab9ccc8f8b",
            "6ac9a75e9e694f90b0e1c0a9c4ac1c3c",
            "2e6b61e193674b23b3f74ac232abbceb",
            "eef312eb689a435d94f40232015fd293"
          ]
        },
        "id": "6a077215-b821-45cf-8747-cd7154f4351a",
        "outputId": "b983e8dd-3ab4-4057-9b16-95c9cc0d81c1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|█         | 1/10 [03:15<29:22, 195.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train epoch: 1, loss: 0.1655, accuracy: 95.16\n",
            " test epoch: 1, loss: 0.07, accuracy: 97.82\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|██        | 2/10 [06:04<24:00, 180.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train epoch: 2, loss: 0.0443, accuracy: 98.71\n",
            " test epoch: 2, loss: 0.04, accuracy: 98.50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|███       | 3/10 [08:28<19:04, 163.45s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train epoch: 3, loss: 0.0291, accuracy: 99.13\n",
            " test epoch: 3, loss: 0.04, accuracy: 98.59\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|████      | 4/10 [11:10<16:18, 163.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train epoch: 4, loss: 0.0196, accuracy: 99.40\n",
            " test epoch: 4, loss: 0.03, accuracy: 98.93\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|█████     | 5/10 [13:42<13:14, 158.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train epoch: 5, loss: 0.0150, accuracy: 99.58\n",
            " test epoch: 5, loss: 0.03, accuracy: 98.96\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|██████    | 6/10 [15:51<09:54, 148.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train epoch: 6, loss: 0.0112, accuracy: 99.71\n",
            " test epoch: 6, loss: 0.04, accuracy: 98.84\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 70%|███████   | 7/10 [18:14<07:20, 146.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train epoch: 7, loss: 0.0090, accuracy: 99.77\n",
            " test epoch: 7, loss: 0.03, accuracy: 98.98\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 80%|████████  | 8/10 [20:26<04:44, 142.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train epoch: 8, loss: 0.0061, accuracy: 99.87\n",
            " test epoch: 8, loss: 0.03, accuracy: 99.05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 90%|█████████ | 9/10 [22:35<02:17, 138.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train epoch: 9, loss: 0.0049, accuracy: 99.90\n",
            " test epoch: 9, loss: 0.03, accuracy: 99.19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [24:43<00:00, 148.40s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train epoch: 10, loss: 0.0042, accuracy: 99.91\n",
            " test epoch: 10, loss: 0.04, accuracy: 98.93\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Import the TQDM progress bar module using automatic notebook detection\n",
        "# Otherwise it would not work..\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "state = create_train_state(init_rng, optimiser, init_dropout)\n",
        "\n",
        "metrics = {\"test_loss\" : [], \"test_accuracy\": [], \"train_loss\":[], \"train_accuracy\":[]}\n",
        "\n",
        "with tqdm(range(1, num_epochs + 1)) as pbar:\n",
        "    for epoch in pbar:\n",
        "        # Use a separate PRNG key to permute image data during shuffling\n",
        "        rng, input_rng = jax.random.split(rng)\n",
        "        dropout_rng, _ = jax.random.split(dropout_rng)\n",
        "        # Run an optimization step over a training batch\n",
        "        state, train_metrics = train_epoch(state, train_ds, batch_size, epoch, input_rng, dropout_rng)\n",
        "        \n",
        "        # Evaluate on the test set after each training epoch\n",
        "        test_loss, test_accuracy = evaluate_model(state.params, test_ds, dropout_rng)\n",
        "        pbar.write('train epoch: %d, loss: %.4f, accuracy: %.2f' % (epoch, train_metrics['loss'], train_metrics['accuracy'] * 100))\n",
        "        pbar.write(' test epoch: %d, loss: %.2f, accuracy: %.2f' % (epoch, test_loss, test_accuracy * 100))\n",
        "\n",
        "        # save data\n",
        "        metrics[\"train_loss\"].append(train_metrics[\"loss\"])\n",
        "        metrics[\"train_accuracy\"].append(train_metrics[\"accuracy\"])\n",
        "        metrics[\"test_loss\"].append(test_loss)\n",
        "        metrics[\"test_accuracy\"].append(test_accuracy)\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d3489436-f20c-4e1b-8d2c-05ac86769fc0",
      "metadata": {
        "id": "d3489436-f20c-4e1b-8d2c-05ac86769fc0"
      },
      "source": [
        "We now want to check the performance of the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aefca0cb-80ed-43df-84de-1b4073a84d54",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aefca0cb-80ed-43df-84de-1b4073a84d54",
        "outputId": "06a49221-82b1-45fb-9524-1c320e12284f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Accuracy')"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 864x216 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, axs = plt.subplots(1,2, figsize=(12,3))\n",
        "\n",
        "axs[0].plot(metrics[\"train_loss\"], label=\"train\")\n",
        "axs[0].plot(metrics[\"test_loss\"], label=\"test\")\n",
        "axs[0].legend()\n",
        "axs[0].set_xlabel(\"Epoch #\")\n",
        "axs[0].set_ylabel(\"Loss\")\n",
        "\n",
        "\n",
        "axs[1].plot(metrics[\"train_accuracy\"], label=\"train\")\n",
        "axs[1].plot(metrics[\"test_accuracy\"], label=\"test\")\n",
        "axs[1].legend()\n",
        "axs[1].set_xlabel(\"Epoch #\")\n",
        "axs[1].set_ylabel(\"Accuracy\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Copie de Copie de 2a-mnist.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "af2da5cc5270e94f5935e371be818e4bec70253d0f779505a7b15694dfa8a491"
    },
    "kernelspec": {
      "display_name": "Python 3.8.3 64-bit ('ml_env': venv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "04701b94470e4411b492e05f32420185": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e6b61e193674b23b3f74ac232abbceb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "320532e08f5549aca2ef73d7eaa1b355": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32c1a0067c3a4e7fba9065e92bdbc018": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_320532e08f5549aca2ef73d7eaa1b355",
            "placeholder": "​",
            "style": "IPY_MODEL_ace16b3606ad493aab790446a3319436",
            "value": " 4/4 [00:00&lt;00:00,  6.58 file/s]"
          }
        },
        "55e80ba5b1cf432a9fb796a67a3f78b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5bd5b0f8ff3441c1be0e851acee6ecde": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "697375ac698e4bc8a872c12933b4a522": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5bd5b0f8ff3441c1be0e851acee6ecde",
            "placeholder": "​",
            "style": "IPY_MODEL_9b160d0b614c4b0eb031b800bfd12aa4",
            "value": "100%"
          }
        },
        "6ac9a75e9e694f90b0e1c0a9c4ac1c3c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78c429eff6024aa2a512b15e9b8e5e9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7d8e72ccff7a4e879b6337b7c5d7c661": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "891bacd221794bbfa89a2f02dbdee926": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91384fa0fe154c09837d63ce7c101eae",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_55e80ba5b1cf432a9fb796a67a3f78b9",
            "value": 4
          }
        },
        "8f1a2792ffd04a798b7bd3ab9ccc8f8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "91384fa0fe154c09837d63ce7c101eae": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b160d0b614c4b0eb031b800bfd12aa4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ace16b3606ad493aab790446a3319436": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "acf2fc1089844f0c9e7790b157c892d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eef312eb689a435d94f40232015fd293",
            "placeholder": "​",
            "style": "IPY_MODEL_2e6b61e193674b23b3f74ac232abbceb",
            "value": " 10/10 [05:00&lt;00:00, 28.54s/it]"
          }
        },
        "ca9e12c942d44da198e547847a9858e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_697375ac698e4bc8a872c12933b4a522",
              "IPY_MODEL_dde09fc3f18f4b1c91fb42f7111e0500",
              "IPY_MODEL_acf2fc1089844f0c9e7790b157c892d6"
            ],
            "layout": "IPY_MODEL_7d8e72ccff7a4e879b6337b7c5d7c661"
          }
        },
        "d7aa4fb804ea4a73996663c5d0822eb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd1bc9bdf2a84c17be8de44ceb04d62f",
            "placeholder": "​",
            "style": "IPY_MODEL_78c429eff6024aa2a512b15e9b8e5e9d",
            "value": "Dl Completed...: 100%"
          }
        },
        "dd1bc9bdf2a84c17be8de44ceb04d62f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dde09fc3f18f4b1c91fb42f7111e0500": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ac9a75e9e694f90b0e1c0a9c4ac1c3c",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8f1a2792ffd04a798b7bd3ab9ccc8f8b",
            "value": 10
          }
        },
        "eef312eb689a435d94f40232015fd293": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fdbbfa9dd9274ac5b5122eb70e8bd166": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d7aa4fb804ea4a73996663c5d0822eb2",
              "IPY_MODEL_891bacd221794bbfa89a2f02dbdee926",
              "IPY_MODEL_32c1a0067c3a4e7fba9065e92bdbc018"
            ],
            "layout": "IPY_MODEL_04701b94470e4411b492e05f32420185"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
